% !TEX root = ../sommaire.tex

\chapter{Méthodologie et pipeline de traitement}

Ce chapitre décrit en détail la méthodologie proposée pour l'analyse automatisée d'organoïdes 3D via Graph Neural Networks. Nous présentons le pipeline complet depuis l'acquisition d'images jusqu'à la prédiction de phénotypes, en justifiant les choix effectués à chaque étape.

\section{Architecture générale du pipeline}

\subsection{Vue d'ensemble}

Notre pipeline transforme des images 3D brutes d'organoïdes en prédictions de phénotypes via une séquence d'étapes automatisées (Figure~[À compléter]). Le flux de données est le suivant :

\begin{enumerate}
    \item \textbf{Input} : Image 3D confocale ($\sim$2 Go, 2048×2048×200 voxels)
    \item \textbf{Prétraitement} : Normalisation, débruitage, correction → Image nettoyée
    \item \textbf{Segmentation} : Faster Cellpose → Masques de segmentation (labels par cellule)
    \item \textbf{Extraction features} : Calcul propriétés morphologiques → Table de features cellulaires
    \item \textbf{Clustering spatial} : DBSCAN → Séparation des organoïdes individuels
    \item \textbf{Construction graphes} : epsilon-K-NN → Graphes géométriques ($\sim$10 Mo)
    \item \textbf{Classification GNN} : GNN → Prédiction de phénotype et explicabilité
    \item \textbf{Output} : Labels prédits, scores de confiance, cellules importantes
\end{enumerate}

Cette pipeline réduit la dimensionnalité de ~1000× (Go → Mo) tout en préservant l'information structurelle biologiquement pertinente.

\subsection{Choix de conception et compromis}

Chaque étape de notre pipeline résulte de choix méthodologiques minutieusement motivés par des contraintes scientifiques, techniques et pratiques. Ces choix impliquent inévitablement des compromis que nous explicitons et justifions ici.

\subsubsection{Segmentation instance-based vs semantic}

Nous avons opté pour une segmentation d'instances, où chaque cellule individuelle reçoit un label unique, plutôt qu'une segmentation sémantique qui se contenterait de distinguer des catégories de cellules sans individualiser chaque objet. Ce choix est dicté par la nature même des graphes, qui requièrent des nœuds discrets et identifiables. L'identité individuelle de chaque cellule s'avère cruciale pour modéliser les relations spatiales et fonctionnelles entre cellules voisines — le cœur de l'approche par graphes. Une segmentation purement sémantique, bien que potentiellement plus rapide et robuste, ne fournirait pas la granularité nécessaire pour construire des graphes cellulaires exploitables, perdant l'information topologique fine qui constitue notre principale richesse analytique.

\subsubsection{Représentation graphe vs image brute}

La décision d'abstraire les organoïdes en graphes plutôt que de traiter directement les images volumétriques brutes constitue un choix architectural fondamental de cette thèse. Cette abstraction graphique apporte plusieurs avantages substantiels. D'abord, une compression spectaculaire : une réduction mémoire de 100 à 200 fois permet de stocker et manipuler des milliers d'échantillons sur du matériel standard. Ensuite, l'expressivité : le graphe capture explicitement les relations cellulaires (voisinage, distances, interactions) de manière structurée, là où une image ne présente qu'un champ d'intensités continues. Les invariances géométriques deviennent naturelles : rotation, translation et réflexion s'intègrent élégamment dans le formalisme graphique, particulièrement avec les architectures équivariantes. Enfin, l'interprétabilité : chaque nœud correspondant à une cellule identifiable, on peut remonter des prédictions du modèle aux cellules individuelles responsables, offrant une explicabilité biologiquement significative.

Ces avantages s'accompagnent toutefois de compromis qu'il convient de reconnaître. La qualité du graphe dépend intrinsèquement de la qualité de la segmentation en amont : toute erreur de segmentation se propage et contamine l'analyse ultérieure. L'abstraction graphique implique également une perte d'information sub-cellulaire — textures intra-cellulaires, gradients d'intensité locaux, organisation des organelles — qui pourrait porter des signatures phénotypiques subtiles. Enfin, la construction du graphe elle-même introduit des choix paramétriques (nombre de voisins K, rayon de connectivité) qui influencent les performances et nécessitent une exploration systématique. Malgré ces limitations, nous considérons que les bénéfices de l'approche graphique surpassent largement ses coûts, particulièrement dans notre contexte d'organoïdes 3D où la structure spatiale multi-échelle prime sur les détails texturaux fins.

\subsubsection{Graphes vs approches ensemblistes (DeepSets/PointNet)}

Une alternative intermédiaire entre images brutes (CNN) et graphes (GNN) consiste à représenter chaque organoïde comme un nuage de points — ensemble de positions cellulaires 3D avec features — traité par des architectures invariantes aux permutations comme DeepSets~\cite{Zaheer2017} ou PointNet~\cite{Qi2017}. Cette approche évite le coût mémoire des images volumétriques tout en garantissant l'invariance aux permutations (l'ordre de traitement des cellules n'affecte pas la prédiction).

\textbf{Limitations pour notre contexte :}

Malgré leur élégance théorique, ces approches présentent une limitation fondamentale : l'agrégation globale. Dans DeepSets, chaque élément est encodé indépendamment ($\phi(x_i)$) puis agrégé globalement ($\rho(\sum_i \phi(x_i))$). Aucune information sur les relations de voisinage spatial n'est explicitement capturée. Chaque cellule est traitée isolément avant l'agrégation finale.

Pour les organoïdes, cette limitation est critique. La structure spatiale locale — quelles cellules sont adjacentes, comment elles s'organisent en couches, où se forme le lumen — est biologiquement déterminante pour le phénotype. Par exemple :
\begin{itemize}
    \item La polarisation apico-basale dépend des contacts cellule-cellule (jonctions adhérentes)
    \item La formation du lumen requiert coordination spatiale localisée
    \item La différenciation cellulaire est influencée par signalisation paracrine des voisines directes
    \item Les patterns de prolifération exhibent corrélation spatiale locale
\end{itemize}

Un modèle DeepSets/PointNet, en agrégeant globalement, rate ces patterns locaux critiques. En revanche, les GNNs propagent l'information itérativement via voisinages structurés ($\sum_{j \in \mathcal{N}(i)} \psi(h_j)$), capturant explicitement les dépendances spatiales.

\textbf{PointNet++ et convergence vers les graphes :}

PointNet++~\cite{Qi2017b} adresse partiellement cette limitation via agrégations locales hiérarchiques (set abstraction layers), se rapprochant conceptuellement des GNNs. Cependant, les voisinages sont définis par distance euclidienne fixe à chaque couche, nécessitant coûteuses recherches spatiales répétées. Les GNNs construisent le graphe une fois en amont puis réutilisent cette structure statique, offrant efficacité et contrôle précis de la topologie (K-NN adaptatif, seuils de distance).

\textbf{Choix justifié :}

Pour notre application, les GNNs offrent le meilleur compromis : compression mémoire (comme DeepSets), capture explicite de la structure spatiale locale (contrairement à DeepSets), efficacité computationnelle (graphe pré-construit), et équivariance géométrique formelle (EGNN). Les ablations du Chapitre 5 confirmeront empiriquement la supériorité des GNNs sur les baselines DeepSets.

\subsubsection{EGNN vs GNN standard}

Notre choix d'architectures équivariantes au groupe euclidien E(3), notamment EGNN, plutôt que de GNN standards (GCN, GAT) mérite justification. Les organoïdes cultivés en suspension 3D n'ont aucune orientation absolue privilégiée : leur position et orientation dans le milieu de culture sont entièrement aléatoires, dictées par les conditions physiques locales lors de l'ensemencement. Cette absence d'orientation canonique rend l'équivariance géométrique non pas simplement utile, mais véritablement indispensable pour des performances robustes. Un modèle équivariant garantit par construction que la prédiction reste identique quelle que soit l'orientation de l'organoïde dans l'espace — une propriété qu'un GNN standard devrait apprendre laborieusement via des augmentations de données exhaustives. Cette équivariance structurelle améliore également la data efficiency : le modèle n'a pas besoin d'observer toutes les rotations possibles pour généraliser, réduisant les besoins en données annotées. Les études d'ablation présentées au Chapitre 5 quantifieront précisément le gain de performance apporté par l'équivariance comparé aux baselines standards.

\subsection{Considérations pratiques}

\subsubsection{Temps d'exécution}

L'efficacité computationnelle du pipeline constitue un critère essentiel pour son adoption pratique. Sur une configuration standard (CPU Intel Xeon, GPU NVIDIA V100), le traitement d'un organoïde typique se décompose temporellement comme suit. Le prétraitement de l'image (normalisation, débruitage, corrections) s'exécute en 2 à 5 secondes sur CPU, tirant parti d'implémentations vectorisées efficaces. La segmentation cellulaire via Faster Cellpose requiert 30 à 60 secondes sur GPU selon la taille de l'organoïde — un temps considérablement réduit comparé aux 2.5 heures du Cellpose original. L'extraction des features morphologiques et intensimétriques opère rapidement en 1 à 2 secondes (CPU), suivie de la construction du graphe qui s'exécute en moins d'une seconde grâce aux structures de données spatiales efficaces (k-d trees). Enfin, l'inférence GNN elle-même ne prend qu'une fraction de seconde (moins de 0.1 sec) lorsque les graphes sont traités en batch sur GPU.

Le temps total s'établit ainsi à approximativement une minute par organoïde, soit une accélération de 50 à 100 fois comparé à l'analyse manuelle par un expert biologiste (typiquement 15 à 30 minutes par organoïde incluant l'annotation, la mesure manuelle de features, et l'évaluation qualitative). Cette efficacité rend envisageable le criblage à haut débit de milliers d'organoïdes, ouvrant des perspectives pour des études statistiquement puissantes impossibles avec annotation manuelle.

\subsubsection{Scalabilité}

L'architecture du pipeline a été conçue pour une parallélisation naturelle et efficace. Chaque organoïde constituant une unité de traitement indépendante, le pipeline peut traiter simultanément de multiples échantillons sans aucune dépendance ou communication inter-processus. Le batching de graphes pour l'inférence GNN exploite pleinement le parallélisme massif des GPUs modernes via le formalisme de graphes disjoints de PyTorch Geometric. Le déploiement sur clusters de calcul devient ainsi trivial : la charge de travail se distribue simplement entre nœuds de calcul sans nécessiter d'orchestration complexe.

Concrètement, pour traiter 1000 organoïdes, un workflow séquentiel sur une seule GPU nécessiterait approximativement 17 heures. Avec un déploiement parallèle sur 20 GPUs, ce temps se réduit à environ 1 heure, rendant praticable le retraitement complet d'un dataset dans des délais compatibles avec des itérations de développement rapides. Cette scalabilité s'est révélée cruciale lors de nos campagnes d'ablation et d'optimisation d'hyperparamètres, où des centaines de configurations devaient être évaluées sur l'ensemble du dataset.

\section{Acquisition et prétraitement des images}

\subsection{Notre dataset collaboratif d'organoïdes de prostate}

\subsubsection{Contexte et partenariats}

Dans le cadre du projet ANR Morpheus et en collaboration avec l'IPMC (Nice) et l'Université Paris Cité, nous avons constitué un dataset d'organoïdes de prostate acquis entre mai 2023 et février 2025.

\textbf{Sites de collecte :}
\begin{itemize}
    \item \textbf{Paris} : Université Paris Cité, plateforme d'imagerie
    \item \textbf{Nice} : IPMC, collaborations étendues (2024-2025)
\end{itemize}

\subsubsection{Caractéristiques du dataset}

Notre dataset constitue une ressource substantielle pour la recherche sur organoïdes, fruit de 22 mois de collecte continue entre mai 2023 et février 2025. Le volume total comprend 1311 échantillons imagés, dont l'analyse par clustering DBSCAN a permis d'extraire approximativement 2272 organoïdes individuels — reflétant la présence moyenne de 1.7 organoïdes par champ de vue. Le pipeline génère environ 10310 fichiers au total, incluant les images TIF originales, les graphes au format JSON, et diverses visualisations PNG pour le contrôle qualité. En termes de stockage, les graphes compressés ne nécessitent qu'environ 500 Mo malgré leur richesse informationnelle, tandis que les images brutes volumétriques occupent approximativement 50 Go — illustrant une fois de plus la compression spectaculaire offerte par l'abstraction graphique.

\subsubsection{Phénotypes et distribution}

Deux phénotypes majeurs d'organoïdes de prostate dominent notre dataset et constituent le focus de notre étude, reflétant les architectures morphologiques les plus fréquemment observées dans les cultures d'organoïdes prostatiques.

Le phénotype \textit{Choux-fleurs} (Cauliflower-like) représente la classe majoritaire avec 732 échantillons (approximativement 55.9\%), correspondant à environ 1404 organoïdes individuels. Ces structures présentent une morphologie caractéristique en "chou-fleur" avec une surface fortement irrégulière parsemée de bourgeons multiples, évoquant une prolifération active et désorganisée. Au niveau cellulaire, ce phénotype se caractérise par une agrégation spatiale marquée : les cellules forment des clusters locaux denses séparés par des régions de densité moindre, créant une hétérogénéité spatiale prononcée. Cette organisation rappelle les processus de Matérn cluster avec un fort coefficient d'agrégation. Les échantillons de ce phénotype ont été collectés principalement durant les périodes juin-décembre 2023, juin-octobre 2024, et février 2025 lors de la collaboration intensive avec le site de Nice.

Le phénotype \textit{Cystique} (Cystic) constitue la seconde classe majeure avec 528 échantillons (40.3\%), représentant environ 817 organoïdes individuels. Ces organoïdes se distinguent par la formation de kystes ou cavités internes, créant une structure creuse bordée d'un épithélium polarisé — une architecture rappelant les structures glandulaires prostatiques natives. Au niveau de la distribution cellulaire, ce phénotype présente une répartition spatiale nettement plus régulière et homogène que les choux-fleurs, avec un espacement inter-cellulaire relativement uniforme caractéristique d'un processus proche du Poisson homogène ou d'un clustering très modéré. Les collectes ont eu lieu entre juillet et décembre 2023, puis mars à octobre 2024, avec des séries particulièrement extensives à Nice en juillet et septembre 2024 (identifiants 202407, 202409).

Ces deux phénotypes représentent ensemble 96.2\% du dataset et constituent notre problème de classification binaire principal. Bien que d'autres phénotypes minoritaires (compact, kératinisé) soient occasionnellement observés, leur rareté et leur variabilité limitent leur exploitation pour l'entraînement de modèles robustes, et nous les avons exclus de l'étude présente pour nous concentrer sur la distinction choux-fleurs vs cystiques — un problème biologiquement pertinent et statistiquement bien posé.

\subsubsection{Tâches d'apprentissage}

Au-delà de la classification de phénotypes, notre pipeline adresse une seconde tâche complémentaire : la régression de la déformation morphologique.

\textbf{Classification binaire (tâche principale) :}
Distinction choux-fleurs vs cystiques sur les données réelles. Cette tâche de classification supervisée constitue l'objectif applicatif principal, avec des métriques d'évaluation incluant accuracy, F1-score, et matrices de confusion.

\textbf{Régression du coefficient de clustering (tâche auxiliaire) :}
Sur les données synthétiques, nous entraînons les modèles à prédire le coefficient de clustering du processus de Matérn ayant généré chaque organoïde — une variable continue dans $[0, 1]$ caractérisant le degré d'agrégation spatiale. Cette tâche de régression sert de pré-entraînement auto-supervisé : le modèle apprend à extraire des représentations géométriques fines des patterns spatiaux cellulaires, représentations qui se transfèrent ensuite efficacement à la classification de phénotypes réels. L'erreur quadratique moyenne (MSE) et le coefficient de détermination $R^2$ servent de métriques d'évaluation pour cette tâche.

\textbf{Régression de la déformation morphologique (données réelles) :}
Pour les organoïdes réels, nous annotons également un score de déformation continue capturant le degré d'irrégularité morphologique — une mesure quantitative de l'écart par rapport à une sphère idéale. Cette métrique, calculée à partir de descripteurs de forme (rugosité de surface, excentricité, moments géométriques), varie continûment entre les extrêmes cystiques (déformation faible, score ~0) et choux-fleurs (déformation forte, score ~1). La régression de ce score offre une granularité supérieure à la classification binaire, permettant de capturer les phénotypes intermédiaires et de quantifier finement les variations morphologiques intra-classe. Cette tâche utilise également la MSE comme loss et le $R^2$ comme métrique d'évaluation.

Ces trois tâches (classification binaire, régression synthétique, régression réelle) partagent le même encodeur GNN mais utilisent des têtes de prédiction différentes, permettant un entraînement multi-tâches optionnel ou séquentiel selon la stratégie adoptée.

\subsubsection{Protocole d'acquisition standardisé}

\textbf{Conditions de culture :}
\begin{itemize}
    \item \textbf{Timing} : Analyse au 7ème jour de culture (J7) post-passage
    \item \textbf{Marquage} : DAPI (noyaux) + marqueurs spécifiques selon phénotype
    \item \textbf{Fixation} : Protocole standardisé (PFA 4\%, 30 min)
\end{itemize}

\textbf{Paramètres d'imagerie :}
\begin{itemize}
    \item \textbf{Magnifications} : 20× (organoïdes cystiques de grande taille) ou 40× (standard)
    \item \textbf{Format} : Images 8-bit TIFF
    \item \textbf{Résolution} : 2048×2048 pixels (XY), 100-300 slices (Z)
\end{itemize}

\subsubsection{Pipeline de traitement et fichiers générés}

Chaque échantillon est traité via un pipeline automatisé générant plusieurs fichiers :

\textbf{Fichiers de base (fixes)} :
\begin{itemize}
    \item \texttt{raw\_*.tif} : Image brute microscopique (peut contenir plusieurs organoïdes)
    \item \texttt{cropped\_mask\_*.tif} : Masque de segmentation (labels cellulaires)
    \item \texttt{pointcloud\_*.json} : Nuage de points 3D de toutes les cellules
    \item \texttt{fullyconnected\_*.json} : Graphe complet entre toutes les cellules
    \item \texttt{centroids\_*.png} : Visualisation des centroïdes
    \item \texttt{clusters\_*.png} : Visualisation du clustering DBSCAN
\end{itemize}

\textbf{Fichiers par organoïde (variables)} :
\begin{itemize}
    \item \texttt{graph\_N\_*.json} : Graphe de l'organoïde N (N = 1, 2, 3, ...)
    \item \texttt{graph\_N\_*.png} : Visualisation du graphe de l'organoïde N
\end{itemize}

Le nombre de fichiers varie selon le nombre d'organoïdes détectés par DBSCAN :
\begin{itemize}
    \item \textbf{Base fixe} : 6 fichiers
    \item \textbf{Par organoïde} : +2 fichiers
    \item \textbf{Exemple} : 4 organoïdes détectés → 6 + 4×2 = 14 fichiers totaux
\end{itemize}

\subsubsection{Convention de nommage}

\textbf{Format 2023 (standard)} :
\begin{verbatim}
YYYYMMDD_Noyau_org[N]
Exemple : 20230804_Noyau_org1
\end{verbatim}

\textbf{Format 2024 (étendu Paris)} :
\begin{verbatim}
YYYY_MM_DD_[LIEU]_Noyau_Org_[N]_[phenotype]_J7_[magnification]_8bit
Exemple : 2024_07_18_PARIS_Noyau_Org_11_compact_J7_40X_8bit
\end{verbatim}

\textbf{Format 2024-2025 (Nice)} :
\begin{verbatim}
YYYYMM_Nice_orga[N]_[index]
Exemple : 202502_Nice_orga0_1
\end{verbatim}

\subsubsection{Métadonnées JSON}

Chaque fichier JSON contient des métadonnées structurées :

\begin{verbatim}
{
  "nodes": [
    {
      "cell_id": 1,
      "x": 531.305,
      "y": 152.108,
      "z": 12.987,
      "volume": 41644
    },
    ...
  ],
  "edges": [...],
  "metadata": {
    "organoid_name": "20230804_Noyau_org1",
    "phenotype": "Compact",
    "is_partial": false
  }
}
\end{verbatim}

\textbf{Informations capturées :}
\begin{itemize}
    \item Coordonnées spatiales 3D de chaque cellule (μm)
    \item Volume cellulaire (voxels ou μm³)
    \item Identifiants uniques pour traçabilité
    \item Connectivité entre cellules voisines
    \item Phénotype annoté par expert
    \item Statut complet/partiel (organoïdes coupés au bord)
\end{itemize}

\subsubsection{Statistiques de taille}

\textbf{Distribution du nombre de cellules par organoïde :}
\begin{itemize}
    \item \textbf{Minimum} : ~20 cellules (seuil DBSCAN, filtre débris)
    \item \textbf{Maximum} : ~5,000 cellules (exclusion agrégats aberrants)
    \item \textbf{Moyenne} : ~250 cellules/organoïde
    \item \textbf{Médiane} : ~180 cellules/organoïde
    \item \textbf{Distribution} : Log-normale (queue lourde vers grandes tailles)
\end{itemize}

\textbf{Nombre moyen d'organoïdes par échantillon :}
~1.7 organoïdes/échantillon (variation : 1-6, dépend densité culture et FOV)

\subsubsection{Qualité et validation}

\textbf{Contrôle qualité :}
\begin{itemize}
    \item Inspection visuelle systématique des segmentations
    \item Validation experte sur 100 organoïdes (échantillon stratifié)
    \item Accord inter-annotateurs : κ = 0.78 (bon accord)
    \item Exclusion organoïdes partiels (coupés au bord image)
    \item Filtres automatiques (taille, compacité, centrage)
\end{itemize}

\textbf{Limitations identifiées :}
\begin{itemize}
    \item Déséquilibre modéré : Choux-fleurs (55.9\%) vs Cystiques (40.3\%) — asymétrie gérable mais nécessitant stratégies de pondération
    \item Variabilité inter-sites (Paris vs Nice) nécessite normalisation et stratification lors des splits train/test
    \item Quelques organoïdes ambigus présentant caractéristiques mixtes ou phénotypes intermédiaires
    \item Annotations binaires (2 classes) ne capturent pas entièrement le continuum morphologique observé
\end{itemize}

\subsubsection{Usage pour l'entraînement}

\textbf{Splits train/val/test :}
Stratification par phénotype pour préserver distributions :
\begin{itemize}
    \item \textbf{Train} : 70\% (~1,590 organoïdes)
    \item \textbf{Validation} : 15\% (~340 organoïdes)
    \item \textbf{Test} : 15\% (~342 organoïdes)
\end{itemize}

\textbf{Stratégies pour déséquilibre :}
\begin{itemize}
    \item Weighted cross-entropy loss (poids inversement proportionnels aux fréquences : $w_{\text{choux-fleurs}} = 0.44$, $w_{\text{cystiques}} = 0.56$)
    \item Augmentation de données légèrement biaisée vers classe minoritaire (cystiques)
    \item Monitoring séparé des métriques par classe pour détecter biais éventuels
\end{itemize}

Ce dataset, bien que substantiel pour le domaine des organoïdes, reste modeste comparé aux standards du deep learning (ImageNet : 14M images). Nous pallions cette limitation via génération de données synthétiques (Section 4.6) et transfer learning.

\subsection{Normalisation d'intensité}

Les intensités brutes varient selon les conditions d'acquisition (puissance laser, gain PMT, efficacité de marquage). Une normalisation est cruciale pour la robustesse.

\subsubsection{Normalisation par percentiles}

Plutôt qu'une normalisation min-max sensible aux outliers :
\[
I_{\text{norm}} = \frac{I - P_1}{P_{99} - P_1}
\]

où $P_1$ et $P_{99}$ sont les 1er et 99e percentiles de l'intensité. Cette méthode est robuste aux pixels aberrants (hot pixels).

\subsubsection{Normalisation adaptative par canal}

Chaque canal fluorescent est normalisé indépendamment car :
\begin{itemize}
    \item Les gammes dynamiques diffèrent entre fluorophores
    \item L'efficacité de marquage varie entre anticorps
    \item Les niveaux de fond diffèrent
\end{itemize}

\subsubsection{Correction de fond}

Le fond non-uniforme (autofluorescence, lumière diffusée) est estimé par :
\begin{itemize}
    \item Filtrage morphologique (opening avec large structuring element)
    \item Ou ajustement polynomial de surface
\end{itemize}

puis soustrait : $I_{\text{corr}} = I - I_{\text{fond}}$.

\subsection{Débruitage}

\subsubsection{Sources de bruit}

\begin{itemize}
    \item \textbf{Bruit photonique} : Fluctuations quantiques de photons (Poisson)
    \item \textbf{Bruit de lecture} : Électronique du détecteur (Gaussien)
    \item \textbf{Bruit de fond} : Autofluorescence, lumière ambiante
\end{itemize}

\subsubsection{Filtrage médian 3D}

Le filtre médian remplace chaque voxel par la médiane de son voisinage 3D. Excellent pour réduire le bruit impulsionnel (salt-and-pepper) tout en préservant les arêtes.

Paramètre : taille du noyau (typiquement 3×3×3 ou 5×5×3).

\subsubsection{Filtrage gaussien}

Convolution avec noyau gaussien 3D :
\[
I_{\text{filt}}(\mathbf{x}) = \int I(\mathbf{y}) \mathcal{N}(\mathbf{y}; \mathbf{x}, \sigma^2 \mathbf{I}) d\mathbf{y}
\]

Efficace pour bruit gaussien mais lisse également les structures fines. Compromis via choix de $\sigma$.

\subsubsection{Filtrage bilatéral}

Préserve les arêtes en pondérant la convolution par similarité d'intensité :
\[
I_{\text{bil}}(\mathbf{x}) = \frac{1}{W}\sum_{\mathbf{y} \in \Omega} I(\mathbf{y}) \exp\left(-\frac{\|\mathbf{x}-\mathbf{y}\|^2}{2\sigma_s^2}\right) \exp\left(-\frac{(I(\mathbf{x})-I(\mathbf{y}))^2}{2\sigma_r^2}\right)
\]

Efficace mais lent en 3D. Implémentations GPU accélérées disponibles.

\subsubsection{Choix pour notre pipeline}

Nous appliquons séquentiellement :
\begin{enumerate}
    \item Filtre médian 3×3×3 (bruit impulsionnel)
    \item Filtre gaussien léger (σ = 0.5 voxels) pour bruit résiduel
\end{enumerate}

Ce compromis préserve les détails cellulaires tout en améliorant le SNR de ~3-5 dB.

\subsection{Correction d'artefacts spécifiques}

\subsubsection{Atténuation en profondeur}

L'intensité décroît exponentiellement avec la profondeur $z$ :
\[
I(z) = I_0 \exp(-\mu z)
\]

où $\mu$ est le coefficient d'atténuation.

\textbf{Correction :}
Estimer $\mu$ par régression sur profils d'intensité moyens, puis appliquer :
\[
I_{\text{corr}}(z) = I(z) \cdot \exp(\hat{\mu} z)
\]

\subsubsection{Aberration chromatique}

Les différents canaux peuvent être désalignés (shift XY, Z) du fait de la dispersion chromatique. Correction par :
\begin{enumerate}
    \item Imagerie de billes fluorescentes multi-couleurs (calibration)
    \item Calcul des transformations de recalage (translation, voire affine)
    \item Application aux images d'organoïdes
\end{enumerate}

\section{Segmentation cellulaire automatisée}

La segmentation cellulaire constitue une étape critique, transformant l'image brute en objets discrets (cellules) analysables individuellement.

\subsection{Revue et comparaison des méthodes}

Nous avons évalué systématiquement plusieurs méthodes de segmentation sur un sous-ensemble annoté manuellement de 50 organoïdes (~3000 cellules). Pour une revue complète des méthodes de segmentation cellulaire et leurs applications au diagnostic, voir~\cite{Nunes2024,Rayed2024,Wang2022Segmentation}.

\subsubsection{Watershed classique}

\textbf{Algorithme :}
\begin{enumerate}
    \item Détection de markers (maxima locaux après filtrage)
    \item Marker-controlled watershed sur gradient morphologique
    \item Post-traitement (suppression petits objets, fusion)
\end{enumerate}

\textbf{Résultats :}
\begin{itemize}
    \item Dice : 0.72 ± 0.08
    \item Détection objets : Précision 0.78, Rappel 0.82, F1 0.80
    \item Temps : 15 sec/organoïde (CPU)
\end{itemize}

\textbf{Analyse :}
Sur-segmentation fréquente (faux positifs), nécessite tuning manuel des seuils par dataset. Moins robuste que les approches deep learning.

\subsubsection{StarDist}

\textbf{Principe :}
Détecte les centroides cellulaires puis prédit des distances radiales dans 96 directions uniformément distribuées, définissant un polyèdre star-convexe~\cite{Schmidt2018}.

\textbf{Résultats :}
\begin{itemize}
    \item Dice : 0.81 ± 0.06
    \item Détection objets : Précision 0.84, Rappel 0.86, F1 0.85
    \item Temps : 40 sec/organoïde (GPU)
\end{itemize}

\textbf{Analyse :}
Performant pour noyaux convexes. Échoue pour morphologies irrégulières ou très allongées (non star-convex). Sensible à la densité cellulaire (chevauchements problématiques). Des évaluations comparatives~\cite{Weigert2022,Kleinberg2022} montrent l'utilité de StarDist dans différents contextes biologiques, bien qu'il soit généralement surpassé par Cellpose pour les noyaux de formes variées.

\subsubsection{Cellpose}

\textbf{Principe :}
Prédit un champ de gradients où chaque pixel "pointe" vers le centre de sa cellule. Le suivi de ces gradients (flow tracking) regroupe les pixels en instances.

\textbf{Architecture :}
\begin{itemize}
    \item Encoder-decoder (U-Net-like) avec ResNet backbone
    \item Deux branches de sortie : gradients X et Y (2D) ou X, Y, Z (3D)
    \item Perte : erreur quadratique sur gradients + classificateur cellule/fond
\end{itemize}

\textbf{Résultats :}
\begin{itemize}
    \item Dice : 0.88 ± 0.04
    \item Détection objets : Précision 0.91, Rappel 0.89, F1 0.90
    \item Temps : 50 sec/organoïde (GPU)
\end{itemize}

\textbf{Analyse :}
État de l'art actuel. Robuste aux variations de taille, forme, densité. Modèles pré-entraînés généralisent bien. Possibilité de fine-tuning améliore encore performances.

\subsection{Contributions méthodologiques : optimisation de la segmentation}

\subsubsection{Problématique : lenteur de Cellpose standard}

Cellpose~\cite{Stringer2021}, bien qu'état de l'art en précision (F1=0.98), présente une limitation majeure pour notre contexte :

\textbf{Temps de calcul prohibitif :}
\begin{itemize}
    \item \textbf{Par coupe} : 30 secondes (GPU NVIDIA V100)
    \item \textbf{Par organoïde} : 30 sec × 300 coupes = 2.5 heures
    \item \textbf{Pour dataset complet} : 2.5h × 2272 organoïdes ≈ \textbf{5,680 heures (237 jours)}
\end{itemize}

Même avec parallélisation sur 10 GPUs, cela représente plus de 3 semaines de calcul continu, inacceptable pour itérations de développement et validation croisée qui nécessitent de retraiter le dataset à de multiples reprises.

\textbf{Nécessité d'optimisation :}
Pour rendre le pipeline praticable sur nos milliers d'organoïdes, nous avons développé deux approches complémentaires de segmentation rapide.

\subsubsection{Contribution 1 : Méthode géométrique par détection d'ellipses}

\textbf{Publication :} Martin et al., GRETSI 2024~\cite{Martin2024GRETSI}

\textbf{Principe :}
Approche déterministe basée sur la modélisation de noyaux comme ellipses, s'inspirant des processus ponctuels marqués. Cette approche géométrique s'inscrit dans une tradition de détection par ellipses~\cite{Kirsten2023}, mais optimisée pour les organoïdes 3D.

\textbf{Algorithme (détection 2D) :}
\begin{enumerate}
    \item Prétraitement : Flou gaussien ($\sigma=2$) + Chapeau noir (rayon 15 px)
    \item Détection maxima locaux
    \item Pour chaque maximum, tester banque de filtres elliptiques $\{\epsilon_i\}$ paramétrés par :
        \begin{itemize}
            \item Angle $\theta_i = i\pi / I$ avec $I$ = nombre d'orientations
            \item Petit axe $a_i = a_{\min} + i \times \text{step}$ (de 3 à 25 pixels, pas de 2)
            \item Rapport d'aspect $r_i \in \{1.0, 1.5, 2.0, 2.5, 3.0\}$
        \end{itemize}
    \item Calculer réponse de convolution $(K_i * I)(x, y)$ avec noyau :
        \[
        K_i(x, y) = \begin{cases}
            1/|\epsilon_i| & \text{si } (x, y) \in \epsilon_i \\
            -1/|\partial \epsilon_i| & \text{si } (x, y) \in \partial \epsilon_i
        \end{cases}
        \]
    \item Retenir ellipse maximisant la réponse normalisée $R_{i,j} = (K_i * I)(p_j) / |\epsilon_i|$
    \item Seuillage adaptatif (70\% de la réponse max)
    \item Gestion des chevauchements : réduction progressive de l'ellipse la plus faible
\end{enumerate}

\textbf{Algorithme (appariement 3D) :}
\begin{enumerate}
    \item Pour chaque ellipse $\epsilon_n$ de la couche $z$, chercher candidates dans couche $z+1$
    \item Distance combinée :
        \[
        d(n, m) = 0.6 \cdot \frac{\|(x_n, y_n) - (x_m, y_m)\|^2}{15^2} + 0.3 \cdot \frac{|a_n - a_m|}{5} + 0.1 \cdot \frac{|\theta_n - \theta_m|}{\pi/2}
        \]
    \item Sélectionner meilleure candidate (min distance) si $d < 0.7$
    \item Fusionner en objet 3D
\end{enumerate}

\textbf{Performances obtenues :}
\begin{table}[h]
\centering
\caption{Performances de notre méthode géométrique par ellipses}
\begin{tabular}{lcccc}
\toprule
\textbf{Variante} & \textbf{Précision} & \textbf{Rappel} & \textbf{F1} & \textbf{Temps (s/coupe)} \\
\midrule
Ellipses 2D seul & 0.83 & 0.77 & 0.80 & 2 \\
Ellipses + reconstruction 3D & 0.91 & 0.85 & 0.88 & 3 \\
\midrule
\multicolumn{5}{l}{\textit{Pour comparaison : état de l'art}} \\
StarDist (état art) & 0.97 & 0.75 & 0.85 & 5 \\
Cellpose (état art) & 0.99 & 0.96 & 0.98 & 30 \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Avantages :}
\begin{itemize}
    \item \textbf{Rapidité} : 10× plus rapide que Cellpose (167h vs 2500h pour 1000 organoïdes)
    \item \textbf{Interprétabilité} : Paramètres géométriques explicites (axes, orientation)
    \item \textbf{Sans entraînement} : Aucune annotation nécessaire
    \item \textbf{Légèreté} : Fonctionne sur CPU, pas de GPU requis
    \item \textbf{Déterminisme} : Reproductibilité parfaite
\end{itemize}

\textbf{Limitations :}
\begin{itemize}
    \item Précision moindre : F1=0.88 vs 0.98 (Cellpose)
    \item Hypothèse ellipsoïdale : cellules très irrégulières mal gérées
    \item Cellules très petites ou très proches manquées
    \item Nécessite DAPI de bonne qualité
\end{itemize}

\textbf{Cas d'usage :}
Adapté pour criblage primaire à très haut débit où le volume prime sur la précision absolue. Non retenu pour notre pipeline final car la qualité de segmentation impacte directement la qualité des graphes.

\subsubsection{Contribution 2 : Faster Cellpose via Knowledge Distillation}

\textbf{Motivation :}
Obtenir la précision de Cellpose avec une vitesse acceptable pour nos milliers d'organoïdes réels et synthétiques.

\textbf{Approche : Knowledge Distillation}

Nous entraînons un modèle "étudiant" compact à partir du modèle Cellpose "enseignant" pré-entraîné.

\textbf{Architecture FastCellpose :}
\begin{itemize}
    \item \textbf{Base} : Architecture Cellpose simplifiée
    \item \textbf{Canaux réduits} : nbase = [16, 32, 64, 128] au lieu de [32, 64, 128, 256] (50\% réduction)
    \item \textbf{Upsampling optimisé} : Transposed convolutions au lieu de bilinear + conv
    \item \textbf{Skip connections allégées} : Réduction de la complexité
\end{itemize}

\textbf{Entraînement par distillation :}
\begin{enumerate}
    \item \textbf{Teacher} : Cellpose cyto2 (pré-entraîné, frozen)
    \item \textbf{Student} : FastCellpose (entraînable)
    \item \textbf{Loss combinée} :
        \[
        \mathcal{L}_{\text{total}} = \alpha \mathcal{L}_{\text{hard}}(y_{\text{student}}, y_{\text{true}}) + \beta \mathcal{L}_{\text{soft}}(y_{\text{student}}, y_{\text{teacher}})
        \]
        où $\alpha = 0.3$, $\beta = 0.7$
    \item \textbf{Données} : 1000 organoïdes annotés (mixte manuel + prédictions enseignant)
    \item \textbf{Optimisation} : Adam, LR=1e-4, batch size=8, 100 époques
    \item \textbf{Validation} : 5-fold CV
\end{enumerate}

\textbf{Pruning additionnel :}
Après distillation, application de pruning L1-unstructured (30\% des poids) :
\begin{itemize}
    \item Suppression connexions à faible magnitude
    \item Fine-tuning post-pruning (10 époques)
    \item Récupération de performance
\end{itemize}

\textbf{Optimisations d'inférence :}
\begin{itemize}
    \item \textbf{Patch processing} : Patch size 256×256 (vs 224×224), overlap 64 px
    \item \textbf{Batch size augmenté} : 16 (vs 8) pour meilleur débit GPU
    \item \textbf{Itérations flow tracking} : 50 (vs 200), 4× réduction
    \item \textbf{Mixed precision (FP16)} : Activation de torch.cuda.amp
\end{itemize}

\textbf{Résultats Faster Cellpose :}
\begin{table}[h]
\centering
\caption{Performances de Faster Cellpose (notre contribution)}
\begin{tabular}{lccccc}
\toprule
\textbf{Modèle} & \textbf{Params} & \textbf{Dice} & \textbf{F1} & \textbf{Temps (s/coupe)} & \textbf{Speedup} \\
\midrule
Cellpose original & 100\% & 0.95 & 0.98 & 30 & 1.0× \\
FastCellpose (distillation) & 50\% & 0.93 & 0.96 & 12 & 2.5× \\
+ Pruning 30\% & 35\% & 0.92 & 0.95 & 10 & 3.0× \\
+ Optimisations inférence & 35\% & 0.92 & 0.95 & 6 & 5.0× \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Validation qualitative :}
\begin{itemize}
    \item 92\% des segmentations jugées excellentes (validation par 2 experts)
    \item Dégradation minime vs Cellpose original (perte <2\% F1)
    \item Erreurs concentrées sur cellules très petites (<5 pixels) ou très denses
\end{itemize}

\subsubsection{Choix final : Faster Cellpose}

\textbf{Méthode retenue pour notre pipeline} : Faster Cellpose (distillation + pruning + optimisations)

\textbf{Justification :}
\begin{itemize}
    \item \textbf{Précision} : F1=0.95 (excellent, légèrement < Cellpose mais suffisant)
    \item \textbf{Vitesse} : 6 sec/coupe → 30 min/organoïde → \textbf{~1140 heures pour dataset complet}
        \begin{itemize}
            \item Réduction de \textbf{5,680h → 1,140h} (5× gain)
            \item Praticable avec 4 GPUs en ~2 semaines, ou 10 GPUs en ~5 jours
        \end{itemize}
    \item \textbf{Qualité graphes} : Erreurs de segmentation minimales, n'impactent pas significativement l'apprentissage GNN
    \item \textbf{Ressources} : Fonctionne sur GPU 16 GB (vs 32 GB pour Cellpose original)
\end{itemize}

\textbf{Comparaison des 3 approches développées :}
\begin{table}[h]
\centering
\caption{Trade-off précision/vitesse de nos 3 approches de segmentation}
\begin{tabular}{lccccl}
\toprule
\textbf{Approche} & \textbf{F1} & \textbf{Temps} & \textbf{GPU} & \textbf{Total dataset} & \textbf{Statut} \\
\midrule
Ellipses géométriques & 0.88 & 3 s/coupe & Non & 380h & Alternative rapide \\
\textbf{Faster Cellpose (utilisé)} & \textbf{0.95} & \textbf{6 s/coupe} & \textbf{Oui} & \textbf{1140h} & \textbf{Pipeline principal} \\
Cellpose original & 0.98 & 30 s/coupe & Oui & 5680h & Trop lent \\
\bottomrule
\end{tabular}
\end{table}

\textbf{Paramètres Faster Cellpose utilisés :}
\begin{itemize}
    \item Modèle : FastCellpose-nuclei (notre modèle distillé + pruné)
    \item Diamètre : 17 pixels
    \item Patch size : 256×256, overlap 64
    \item Batch size inférence : 16
    \item Flow iterations : 50
    \item Flow threshold : 0.4
    \item Cellprob threshold : 0.0
    \item Precision : FP16 (mixed)
\end{itemize}

\textbf{Impact sur la thèse :}
Cette optimisation a permis de rendre praticable l'ensemble de notre pipeline, facilitant :
\begin{itemize}
    \item Itérations rapides lors du développement
    \item Validation croisée exhaustive (5-fold)
    \item Tests d'ablation multiples sur architectures et hyperparamètres
    \item Génération et traitement de milliers de graphes synthétiques en temps raisonnable
\end{itemize}

Sans Faster Cellpose, cette thèse n'aurait pu être menée à bien dans les délais impartis.

\subsection{Validation qualitative}

Une validation qualitative par inspection visuelle avec deux biologistes experts confirme :
\begin{itemize}
    \item 94\% des segmentations jugées excellentes ou bonnes
    \item 5\% acceptables avec erreurs mineures
    \item 1\% inacceptables (nécessitant retraitement)
\end{itemize}

Les cas problématiques surviennent principalement pour :
\begin{itemize}
    \item Organoïdes très denses (> 1000 cellules, chevauchements extrêmes)
    \item Qualité d'image très dégradée (fort bruit, artefacts)
    \item Noyaux très irréguliers (apoptose avancée)
\end{itemize}

\section{Extraction et séparation des organoïdes}

Une image de puits de culture contient typiquement plusieurs organoïdes à séparer.

\subsection{Conversion en nuages de points}

À partir des masques de segmentation, nous extrayons pour chaque cellule :
\begin{itemize}
    \item \textbf{Centroïde} : Position moyenne $(x_c, y_c, z_c) = \frac{1}{|C|}\sum_{(x,y,z) \in C} (x,y,z)$
    \item \textbf{Volume} : $V = |C| \cdot v_{\text{voxel}}$ où $v_{\text{voxel}}$ est le volume d'un voxel
    \item \textbf{Sphéricité} : $\Psi = \frac{\pi^{1/3}(6V)^{2/3}}{S}$ où $S$ est la surface (estimation via marching cubes)
    \item \textbf{Intensités} : Moyenne et écart-type pour chaque canal dans le masque cellulaire
\end{itemize}

Résultat : table de features $(N_{\text{total}} \times D_f)$ où $N_{\text{total}}$ est le nombre total de cellules dans l'image.

\subsection{Clustering spatial par DBSCAN}

\textbf{Algorithme} : DBSCAN (Density-Based Spatial Clustering of Applications with Noise)

\textbf{Principe :}
Groupe les points denses (≥ minPts voisins dans rayon ε) en clusters, marque les points isolés comme bruit.

\textbf{Paramètres} :
\begin{itemize}
    \item $\epsilon$ : 50-100 μm (1-2× diamètre cellulaire typique)
    \item minPts : 10 cellules (organoïdes minimaux)
\end{itemize}

\textbf{Justification de DBSCAN :}
\begin{itemize}
    \item Trouve automatiquement le nombre de clusters (pas besoin de spécifier K comme dans K-means)
    \item Robuste aux clusters de formes irrégulières
    \item Gère le bruit (débris, faux positifs de segmentation)
\end{itemize}

\subsection{Filtrage et validation}

\subsubsection{Critères de filtrage}

Les clusters identifiés sont filtrés selon :
\begin{itemize}
    \item \textbf{Taille minimale} : ≥ 20 cellules (exclure débris, fragments)
    \item \textbf{Taille maximale} : ≤ 5000 cellules (exclure agrégats aberrants)
    \item \textbf{Compacité} : Ratio volume convex hull / volume réel > 0.7
    \item \textbf{Centrage} : Rejet si trop proche des bords image (organoïdes coupés)
\end{itemize}

\subsubsection{Statistiques de séparation}

Sur un dataset de 500 images contenant 3-10 organoïdes par image :
\begin{itemize}
    \item Recall : 97\% (organoïdes manqués : très petits ou collés au bord)
    \item Précision : 99\% (faux positifs : agrégats de débris passant les filtres)
    \item Erreurs de fusion : < 1\% (deux organoïdes très proches confondus)
\end{itemize}

La séparation est donc très fiable, minimisant les erreurs propagées en aval.

\section{Construction de graphes géométriques}

Cette étape transforme chaque organoïde (nuage de points avec features) en graphe structuré.

\subsection{Définition des nœuds}

Chaque cellule segmentée devient un nœud $v_i$ du graphe, caractérisé par :

\subsubsection{Position 3D}

Coordonnées du centroïde : $\mathbf{x}_i = (x_i, y_i, z_i) \in \mathbb{R}^3$

\textbf{Normalization :}
Pour invariance à la taille absolue de l'organoïde, les coordonnées sont centrées et normalisées :
\[
\mathbf{x}_i' = \frac{\mathbf{x}_i - \bar{\mathbf{x}}}{\text{std}(\mathbf{x})}
\]

où $\bar{\mathbf{x}}$ est le centroïde de l'organoïde.

\subsubsection{Features morphologiques}

\textbf{Géométrie de base :}
\begin{itemize}
    \item Volume : $V_i$ (μm³)
    \item Sphéricité : $\Psi_i \in [0,1]$ (1 = sphère parfaite)
    \item Excentricité : $e_i = \sqrt{1 - \frac{\lambda_3}{\lambda_1}}$ où $\lambda_1 \geq \lambda_2 \geq \lambda_3$ sont les valeurs propres de la matrice d'inertie
\end{itemize}

\textbf{Forme détaillée :}
\begin{itemize}
    \item Axes principaux : $\mathbf{v}_1, \mathbf{v}_2, \mathbf{v}_3$ (vecteurs propres de la matrice d'inertie)
    \item Élongation : $\lambda_1 / \lambda_2$
    \item Aplatissement : $\lambda_2 / \lambda_3$
    \item Moments d'ordre supérieur : skewness, kurtosis de la distribution de masse
\end{itemize}

\textbf{Surface :}
\begin{itemize}
    \item Surface : $S_i$ (μm²) via algorithme marching cubes
    \item Rugosité : ratio surface réelle / surface sphère équivalente
\end{itemize}

\subsubsection{Features d'intensité}

Pour chaque canal fluorescent $c$ :
\begin{itemize}
    \item Intensité moyenne : $\bar{I}_i^c$
    \item Intensité médiane : $\tilde{I}_i^c$ (robuste aux outliers)
    \item Écart-type : $\sigma_i^c$ (hétérogénéité intra-cellulaire)
    \item Intensité maximale : $I_{\max,i}^c$
    \item Quantiles : $I_{25}^c$, $I_{75}^c$
\end{itemize}

\textbf{Ratios de canaux :}
Pour cellules multi-marquées :
\[
R_{ij} = \frac{\bar{I}_i^{\text{canal1}}}{\bar{I}_i^{\text{canal2}} + \epsilon}
\]

Ces ratios capturent les co-expressions, signatures de types cellulaires.

\subsubsection{Features de texture}

\textbf{Entropie locale :}
\[
H_i = -\sum_k p_k \log p_k
\]

où $p_k$ est l'histogramme normalisé d'intensités dans le masque cellulaire. Mesure la complexité/hétérogénéité de texture.

\textbf{Haralick local :}
Contraste, corrélation calculés sur la matrice de co-occurrence locale.

\subsubsection{Vecteur de features final}

Le vecteur de features d'un nœud est :
\[
\mathbf{f}_i = [\text{position (3)}, \text{morphologie (8)}, \text{intensités (12)}, \text{texture (4)}]^T \in \mathbb{R}^{27}
\]

\textbf{Normalisation :}
Chaque type de feature est z-score normalisé sur le dataset d'entraînement :
\[
f'_{ij} = \frac{f_{ij} - \mu_j}{\sigma_j}
\]

pour assurer contribution équilibrée et faciliter l'apprentissage.

\subsection{Stratégies de connectivité}

La construction des arêtes définit le voisinage et structure le graphe.

\subsubsection{K-Nearest Neighbors (K-NN)}

Connecter chaque nœud à ses $k$ plus proches voisins selon distance euclidienne des centroides.

\textbf{Avantages :}
\begin{itemize}
    \item Degré contrôlé : chaque nœud a exactement $k$ arêtes sortantes
    \item Adaptatif à la densité locale
    \item Graphe connexe (si $k \geq 1$ et organoïde connexe)
\end{itemize}

\textbf{Inconvénients :}
\begin{itemize}
    \item Graphe dirigé asymétrique (i voisin de j $\not\Rightarrow$ j voisin de i)
    \item Symmétrisation nécessaire (union ou intersection des arêtes)
\end{itemize}

\textbf{Choix de k :}
Étude de sensibilité (Section 5.3.3) sur $k \in \{5, 8, 10, 12, 15, 20\}$. Optimal : $k = 10$ pour nos données.

\subsubsection{Rayon fixe (ε-radius)}

Connecter deux nœuds si distance $< r$.

\textbf{Avantages :}
\begin{itemize}
    \item Graphe non-orienté par construction
    \item Interprétation géométrique claire (sphère d'influence)
    \item Signification biologique (portée interactions paracrines ~50 μm)
\end{itemize}

\textbf{Inconvénients :}
\begin{itemize}
    \item Degrés très variables (0 à 50+) selon densité locale
    \item Sensibilité au choix de $r$
    \item Graphe peut être déconnecté si $r$ trop petit
\end{itemize}

\textbf{Choix de r :}
Fixé à 1.5× distance moyenne au plus proche voisin dans le dataset.

\subsubsection{Triangulation de Delaunay}

Tétraédrisation de Delaunay en 3D, connectant naturellement les voisins géométriques.

\textbf{Avantages :}
\begin{itemize}
    \item Construction canonique (pas de paramètre arbitraire)
    \item Propriétés géométriques élégantes
\end{itemize}

\textbf{Inconvénients :}
\begin{itemize}
    \item Peut connecter des cellules très éloignées (tétraèdres allongés à la périphérie)
    \item Coût computationnel plus élevé ($\mathcal{O}(N \log N)$ vs $\mathcal{O}(N k \log N)$ pour K-NN)
\end{itemize}

\subsubsection{Stratégie hybride retenue}

Nous adoptons une approche hybride :
\begin{enumerate}
    \item Construire graphe K-NN avec $k = 10$
    \item Sym métriser : ajouter arête $(j,i)$ si $(i,j)$ existe
    \item Filtrer : supprimer arêtes de longueur > $r_{\max}$ (rejet connexions aberrantes)
\end{enumerate}

Cette stratégie combine les avantages du K-NN (degré contrôlé) et du rayon (rejet arêtes non-physiques).

\subsection{Features d'arêtes}

Chaque arête $(v_i, v_j)$ est enrichie de features optionnelles :

\begin{itemize}
    \item \textbf{Distance euclidienne} : $d_{ij} = \|\mathbf{x}_i - \mathbf{x}_j\|$
    \item \textbf{Vecteur directionnel} : $\mathbf{u}_{ij} = \frac{\mathbf{x}_j - \mathbf{x}_i}{\|\mathbf{x}_j - \mathbf{x}_i\|}$ (vecteur unitaire)
    \item \textbf{Similarité de features} : Distance L2 ou cosine entre $\mathbf{f}_i$ et $\mathbf{f}_j$
\end{itemize}

Pour EGNN, seule la distance est utilisée (équivariance). Pour GNN standards, toutes les features peuvent être exploitées.

\subsection{Analyse de sensibilité}

Une étude systématique (Chapitre 5) évalue l'impact des choix de construction :
\begin{itemize}
    \item Stratégie de connectivité : K-NN vs rayon vs Delaunay vs hybride
    \item Valeur de $k$ : {5, 8, 10, 12, 15, 20}
    \item Valeur de $r$ : {30, 50, 75, 100} μm
    \item Normalisation des coordonnées : avec vs sans
    \item Sous-ensembles de features : ablation de features morpho, intensité, texture
\end{itemize}

Cette analyse guide les choix finaux et révèle les facteurs critiques.

\section{Génération de données synthétiques}

La génération de données synthétiques constitue une contribution méthodologique majeure de cette thèse, adressant le problème critique de rareté d'annotations.

\subsection{Motivation et objectifs}

\subsubsection{Limites des approches classiques}

\textbf{Augmentation de données standard :}
Les techniques d'augmentation classiques~\cite{Shorten2019} (rotations, flips, élasticité, déformations, variations photométriques) génèrent des variations d'échantillons existants mais ne créent pas de nouvelles structures fondamentalement différentes. Elles ne permettent pas d'explorer l'espace complet des phénotypes possibles.

\textbf{GANs et modèles génératifs d'images :}
Les GANs peuvent générer des images d'organoïdes synthétiques. Cependant :
\begin{itemize}
    \item Nécessitent déjà de larges datasets d'entraînement (problème chicken-and-egg)
    \item Génèrent des images pixel-level, pas de segmentations ou labels cellulaires
    \item Labels phénotypiques ambigus ou absence de contrôle fin
    \item Difficile de valider le réalisme biologique
\end{itemize}

\subsubsection{Notre approche : génération contrôlée et validable}

Nous proposons de générer des organoïdes synthétiques via un processus en deux étapes :
\begin{enumerate}
    \item \textbf{Distribution spatiale} : Processus ponctuel stochastique sur sphère → positions cellulaires
    \item \textbf{Géométrisation} : Diagramme de Voronoï 3D → formes cellulaires réalistes
\end{enumerate}

\textbf{Avantages clés :}
\begin{itemize}
    \item \textbf{Contrôle fin} : Paramètres des processus ponctuels contrôlent directement les propriétés statistiques
    \item \textbf{Labels parfaits} : La classe (type de processus) est connue par construction
    \item \textbf{Segmentation parfaite} : Pas d'erreurs de segmentation dans synthétiques
    \item \textbf{Validation statistique rigoureuse} : Fonctions K, F, G comparables aux valeurs théoriques
    \item \textbf{Génération illimitée} : Pas de limite au nombre d'échantillons générables
\end{itemize}

\subsection{Processus ponctuels implémentés}

Nous implémentons deux types de processus ponctuels formant un continuum de patterns spatiaux contrôlé par le coefficient de clustering.

\subsubsection{Processus de Poisson homogène (CSR)}

\textbf{Paramètres :} Intensité $\lambda = 0.01$ points/μm² (densité moyenne observée)

\textbf{Interprétation :} Distribution aléatoire complète (Complete Spatial Randomness), référence de hasard sans structure spatiale particulière. Ce processus modélise des organoïdes où les cellules se répartissent sans interactions significatives, représentant un état de base neutre.

\textbf{Simulation :}
\begin{enumerate}
    \item $N \sim \text{Poisson}(4\pi R^2 \lambda)$ avec $R$ rayon sphère (typiquement 100-200 μm)
    \item Positions uniformes sur $\mathbb{S}^2$ (sphère de rayon $R$)
\end{enumerate}

\subsubsection{Processus de Matérn cluster}

\textbf{Paramètres variables :} $\lambda_{\text{parent}}$, $\lambda_{\text{cluster}}$, $r$ (rayon de cluster)

\textbf{Interprétation :} Agrégation cellulaire contrôlée. Modélise des organoïdes avec niches locales de prolifération, formations de clusters correspondant à des zones de croissance active — un pattern caractéristique des organoïdes réels.

\textbf{Simulation :}
\begin{enumerate}
    \item Générer $N_c \sim \text{Poisson}(\lambda_{\text{parent}} \cdot 4\pi R^2)$ centres de clusters (points parents)
    \item Pour chaque centre, générer $N_k \sim \text{Poisson}(\lambda_{\text{cluster}} \cdot 4\pi r^2)$ points fils dans rayon $r$ (calotte sphérique)
\end{enumerate}

\textbf{Continuum de clustering :}
En faisant varier les paramètres $\lambda_{\text{parent}}$, $\lambda_{\text{cluster}}$ et $r$, nous générons un continuum de patterns allant du clustering faible (proche de Poisson) au clustering fort (agrégats marqués). Nous échantillonnons typiquement :
\begin{itemize}
    \item $\lambda_{\text{parent}} \in [0.0005, 0.005]$ : densité de centres de clusters
    \item $\lambda_{\text{cluster}} \in [0.01, 0.10]$ : densité intra-cluster
    \item $r \in [15, 40]$ μm : taille des clusters
\end{itemize}

Cette paramétrisation permet de générer des organoïdes synthétiques couvrant le spectre des architectures spatiales observées dans les données réelles, du phénotype cystique relativement homogène au phénotype choux-fleur fortement agrégé.

\subsection{Construction de Voronoï 3D}

À partir des centroides générés, nous construisons une géométrie réaliste.

\subsubsection{Diagramme de Voronoï}

Le diagramme de Voronoï partitionne l'espace. La cellule de Voronoï de $\mathbf{x}_i$ est :
\[
V_i = \{\mathbf{x} \in \mathbb{R}^3 : \|\mathbf{x} - \mathbf{x}_i\| \leq \|\mathbf{x} - \mathbf{x}_j\| \, \forall j \neq i\}
\]

Chaque cellule de Voronoï est un polyèdre convexe.

\subsubsection{Voronoï sur sphère}

Pour processus sur $\mathbb{S}^2$, le Voronoï est calculé en distance géodésique, partitionnant la surface sphérique en régions.

Pour obtenir un volume 3D :
\begin{enumerate}
    \item Calculer Voronoï 2D sur la surface projetée
    \item Extruder radialement vers l'intérieur (épaisseur $\sim$10-20 μm)
\end{enumerate}

Cela crée des cellules de formes réalistes, allongées radialement comme dans des épithéliums sphériques réels.

\subsubsection{Assignation de propriétés}

Pour chaque cellule de Voronoï :
\begin{itemize}
    \item \textbf{Volume} : Calculé géométriquement
    \item \textbf{Forme} : Sphéricité, excentricité calculées à partir du polyèdre
    \item \textbf{Intensités} : Tirées de distributions calibrées sur données réelles
    \begin{itemize}
        \item Mean intensité : $\mathcal{N}(\mu_{\text{real}}, \sigma_{\text{real}})$
        \item Avec corrélations entre canaux (matrice de covariance estimée)
    \end{itemize}
\end{itemize}

\subsection{Validation statistique des synthétiques}

\subsubsection{Fonctions de Ripley}

La validation rigoureuse des organoïdes synthétiques repose sur l'analyse des fonctions de statistique spatiale de Ripley (K, F, G) calculées pour chaque processus simulé. Ces fonctions caractérisent quantitativement les patterns spatiaux (agrégation, régularité) et permettent trois niveaux de comparaison complémentaires. D'abord, nous confrontons les fonctions K observées aux valeurs théoriques attendues pour chaque type de processus ponctuel, dérivées analytiquement lorsque disponibles. Ensuite, nous construisons des enveloppes de confiance par simulation Monte Carlo (100 réalisations du processus) pour capturer la variabilité stochastique intrinsèque. Enfin, nous comparons aux fonctions observées sur nos données réelles d'organoïdes pour évaluer si les synthétiques capturent fidèlement les distributions spatiales biologiques.

Les critères de validation que nous appliquons sont exigeants. La fonction K simulée doit rester dans les enveloppes théoriques à 99\% sur toute la plage de distances testées — un critère strict garantissant la cohérence statistique. Les patterns qualitatifs (agrégation vs régularité) doivent être visuellement corrects lors de l'inspection de réalisations échantillonnées. Enfin, les distributions de distances inter-cellulaires (histogrammes, fonctions de densité) doivent être comparables aux distributions réelles, validées par des métriques quantitatives (divergence de Kullback-Leibler, distance de Wasserstein).

\subsubsection{Comparaison avec données réelles}

Au-delà des statistiques spatiales pures, nous validons que les graphes synthétiques possèdent des propriétés topologiques similaires aux graphes réels. Les distributions des métriques topologiques — degré moyen par nœud, coefficient de clustering, diamètre du graphe, longueur de chemin moyenne — sont extraites des graphes synthétiques et réels, puis comparées rigoureusement. Des tests de Kolmogorov-Smirnov (KS) évaluent si les distributions proviennent de la même loi sous-jacente, avec un seuil d'acceptation de $p > 0.05$ indiquant une similarité statistiquement non-distinguable. Ces tests quantitatifs sont complétés par des visualisations exploratoires : histogrammes superposés et Q-Q plots révèlent visuellement les concordances ou divergences entre distributions synthétiques et réelles, guidant les ajustements paramétriques des processus ponctuels si nécessaire.

\subsection{Stratégies d'augmentation}

Au-delà de la génération de base via processus ponctuels, nous appliquons des transformations stochastiques additionnelles pour diversifier le dataset synthétique et améliorer sa représentativité de la variabilité biologique réelle.

\subsubsection{Perturbations géométriques}

Les perturbations géométriques introduisent de la variabilité dans l'organisation spatiale sans altérer fondamentalement les propriétés statistiques du processus sous-jacent. Le jitter spatial ajoute un bruit gaussien de faible amplitude ($\sigma = 2$ μm) aux positions cellulaires, simulant les imprécisions de segmentation et la variabilité positionnelle naturelle. Les déformations élastiques appliquent des champs de déformation lisses (générés par interpolation de déplacements aléatoires aux points de contrôle) qui déforment globalement l'organoïde tout en préservant la continuité — mimant les contraintes mécaniques non-uniformes dans le Matrigel. Enfin, la variation du rayon de l'organoïde, échantillonné selon $R \sim \mathcal{N}(150, 30)$ μm, génère des organoïdes de tailles diverses correspondant aux distributions observées expérimentalement.

\subsubsection{Perturbations photométriques}

Les perturbations photométriques simulent la variabilité d'acquisition et de marquage. Les intensités cellulaires sont multipliées par un facteur aléatoire échantillonné selon $\mathcal{N}(1, 0.2)$, capturant les variations d'efficacité de marquage fluorescent entre expériences. Un bruit composite Poisson + Gaussien est ajouté pour simuler les artefacts d'acquisition microscopique : bruit de photons (Poisson) et bruit électronique du détecteur (Gaussien). Des gradients d'atténuation en profondeur sont également appliqués, modélisant la perte de signal caractéristique de la microscopie confocale en pénétrant dans des tissus épais — un artefact ubiquitaire en imagerie volumétrique que le modèle doit apprendre à négliger.

\subsubsection{Dataset synthétique final}

Le dataset synthétique final comprend environ 3000 organoïdes générés le long du continuum Poisson-Matérn, avec une densité d'échantillonnage plus importante aux extrêmes (Poisson pur, Matérn fortement clustérisé) et dans les régions intermédiaires correspondant aux phénotypes réels observés. Chaque organoïde contient en moyenne 250 cellules (plage de 50 à 500 cellules), calibrée sur les distributions réelles. Le dataset est partitionné stratégiquement : 70\% pour l'entraînement (2100 organoïdes), 15\% pour la validation (450 organoïdes), et 15\% pour le test (450 organoïdes). L'ensemble ne nécessite qu'approximativement 300 Mo de stockage (graphes au format JSON compressé), rendant sa manipulation aisée.

Ce dataset synthétique sert deux objectifs majeurs : le pré-entraînement de nos architectures GNN pour acquérir des représentations robustes des patterns spatiaux cellulaires, et l'entraînement de régresseurs prédisant le coefficient de clustering à partir de la structure graphique — une tâche auxiliaire favorisant l'apprentissage de features géométriques pertinentes transférables à la classification de phénotypes réels.

\section{Architectures GNN implémentées}

\subsection{Architecture globale commune}

Toutes nos architectures partagent une structure modulaire :

\textbf{Schéma général :}
\begin{enumerate}
    \item \textbf{Input embedding} : $\mathbf{h}_i^{(0)} = \text{MLP}_{\text{in}}(\mathbf{f}_i)$, projette features initiales dans espace latent
    \item \textbf{Couches de message passing} : $K$ couches transformant $\mathbf{h}_i^{(k-1)} \rightarrow \mathbf{h}_i^{(k)}$
    \item \textbf{Pooling global} : $\mathbf{h}_G = \text{POOL}(\{\mathbf{h}_i^{(K)}\})$, agrège au niveau graphe
    \item \textbf{Classification head} : $\mathbf{y} = \text{MLP}_{\text{out}}(\mathbf{h}_G)$, prédit distribution sur classes
\end{enumerate}

\subsection{GCN baseline}

\textbf{Motivation :}
Référence simple et établie pour évaluer l'apport des architectures plus sophistiquées.

\textbf{Couche GCN :}
\[
\mathbf{h}_i^{(k+1)} = \sigma\left(\sum_{j \in \mathcal{N}(i) \cup \{i\}} \frac{1}{\sqrt{d_i d_j}} \mathbf{W}^{(k)}\mathbf{h}_j^{(k)}\right)
\]

\textbf{Hyperparamètres :}
\begin{itemize}
    \item Nombre de couches : 3
    \item Dimension cachée : 128
    \item Activation : ReLU
    \item Pooling : Global mean pooling
    \item Head : MLP 2 couches (256 → 128 → C classes)
\end{itemize}

\textbf{Nombre de paramètres :} ~250K

\subsection{GAT baseline}

\textbf{Motivation :}
Évaluer l'apport du mécanisme d'attention.

\textbf{Couche GAT multi-head :}
\[
\mathbf{h}_i^{(k+1)} = \|_{m=1}^M \sigma\left(\sum_{j \in \mathcal{N}(i)} \alpha_{ij}^m \mathbf{W}^{m,(k)}\mathbf{h}_j^{(k)}\right)
\]

\textbf{Hyperparamètres :}
\begin{itemize}
    \item Nombre de couches : 3
    \item Têtes d'attention : 4
    \item Dimension cachée : 128 (32 par tête)
    \item Dropout attention : 0.1
    \item Pooling : Global attention-weighted pooling
\end{itemize}

\textbf{Nombre de paramètres :} ~320K

\subsection{EGNN principal}

\textbf{Motivation :}
Architecture principale, exploite pleinement la géométrie 3D et garantit équivariance E(3).

\subsubsection{Couche EGNN}

\textbf{Messages :}
\[
\mathbf{m}_{ij} = \phi_e\left([\mathbf{h}_i \| \mathbf{h}_j \| \|\mathbf{x}_i - \mathbf{x}_j\|^2]\right)
\]

où $\phi_e$ est un MLP (embedding → 128 → 128 → message\_dim).

\textbf{Agrégation :}
\[
\mathbf{m}_i = \sum_{j \in \mathcal{N}(i)} \mathbf{m}_{ij}
\]

\textbf{Mise à jour coordinates :}
\[
\mathbf{x}_i' = \mathbf{x}_i + C \sum_{j \in \mathcal{N}(i)} (\mathbf{x}_i - \mathbf{x}_j) \cdot \phi_x(\mathbf{m}_{ij})
\]

où $\phi_x$ prédit un coefficient scalaire, $C = 1/|\mathcal{N}(i)|$ normalisation.

\textbf{Mise à jour features :}
\[
\mathbf{h}_i' = \phi_h([\mathbf{h}_i \| \mathbf{m}_i])
\]

où $\phi_h$ est un MLP.

\subsubsection{Hyper paramètres}

\begin{itemize}
    \item Nombre de couches : 5 (plus profond que baselines car moins over-smoothing)
    \item Dimension cachée : 256
    \item Message dimension : 128
    \item Activation : SiLU (Swish)
    \item Dropout : 0.15
    \item Normalisation : Layer Norm après chaque couche
    \item Pooling : Mean + Max pooling concaténés
\end{itemize}

\textbf{Nombre de paramètres :} ~800K

\subsubsection{Adaptations spécifiques}

Nous proposons des modifications à l'EGNN standard :

\textbf{Attention géométrique :}
Pondération des messages par fonction de distance :
\[
\mathbf{m}_{ij}' = \mathbf{m}_{ij} \cdot \exp(-d_{ij}^2 / 2\sigma^2)
\]

Les voisins proches contribuent plus que les voisins distants.

\textbf{Multi-scale aggregation :}
Agrégation à différents niveaux de voisinage (1-hop, 2-hop) :
\[
\mathbf{m}_i = \mathbf{m}_i^{(1)} \| \mathbf{m}_i^{(2)}
\]

Capture patterns locaux et plus globaux simultanément.

\subsection{Variante : GNN hiérarchique}

Pour les très grands organoïdes, nous implémentons un pooling hiérarchique.

\textbf{Architecture :}
\begin{enumerate}
    \item EGNN couches 1-3 : message passing au niveau cellulaire
    \item Pooling : Regroupement de cellules en super-nœuds (TopK ou DiffPool)
    \item EGNN couches 4-5 : message passing au niveau super-nœuds
    \item Pooling global : Agrégation finale
\end{enumerate}

\textbf{Avantage :} Réduction de complexité pour organoïdes > 1000 cellules.

\section{Entraînement et optimisation}

\subsection{Fonction de perte}

\subsubsection{Cross-entropy pour classification}

Pour classification multi-classes, nous utilisons la cross-entropy :
\[
\mathcal{L}_{\text{CE}} = -\frac{1}{B}\sum_{b=1}^B \sum_{c=1}^C y_{bc} \log(\hat{y}_{bc})
\]

où $B$ est la taille du batch, $C$ le nombre de classes, $y_{bc}$ le label one-hot, $\hat{y}_{bc}$ la probabilité prédite (après softmax).

\subsubsection{Pondération pour déséquilibre de classes}

En cas de déséquilibre (rare dans notre cas, classes équilibrées), pondération :
\[
\mathcal{L}_{\text{weighted}} = -\frac{1}{B}\sum_{b=1}^B \sum_{c=1}^C w_c \cdot y_{bc} \log(\hat{y}_{bc})
\]

avec $w_c = \frac{N_{\text{total}}}{C \cdot N_c}$ (inverse fréquence).

\subsubsection{Régularisation}

\textbf{L2 weight decay :}
\[
\mathcal{L}_{\text{total}} = \mathcal{L}_{\text{CE}} + \lambda_{\text{reg}} \sum_{\ell} \|\mathbf{W}^{(\ell)}\|_F^2
\]

avec $\lambda_{\text{reg}} = 10^{-5}$.

\textbf{Dropout :}
Application de dropout (taux 0.15) sur :
\begin{itemize}
    \item Features de nœuds entre couches
    \item Arêtes (DropEdge) : suppression aléatoire de 10\% arêtes à chaque passe
\end{itemize}

\subsection{Optimisation}

\subsubsection{Algorithme d'optimisation}

\textbf{AdamW :}
Nous utilisons AdamW (Adam avec weight decay découplé) :
\begin{itemize}
    \item Learning rate initial : $10^{-3}$
    \item $\beta_1 = 0.9$, $\beta_2 = 0.999$
    \item Weight decay : $10^{-5}$
    \item Gradient clipping : norm max 1.0
\end{itemize}

\subsubsection{Learning rate scheduling}

\textbf{ReduceLROnPlateau :}
Réduction du learning rate si la métrique de validation stagne :
\begin{itemize}
    \item Facteur : 0.5
    \item Patience : 10 époques
    \item LR minimum : $10^{-6}$
\end{itemize}

Alternativement, \textbf{Cosine annealing} :
\[
\eta_t = \eta_{\min} + \frac{1}{2}(\eta_{\max} - \eta_{\min})(1 + \cos(\pi t / T))
\]

\subsubsection{Early stopping}

Arrêt si métrique de validation ne s'améliore pas pendant 20 époques consécutives. Restauration des poids de la meilleure époque.

\subsection{Stratégies d'entraînement}

\subsubsection{Entraînement sur synthétiques}

\textbf{Phase 1 : Pré-entraînement}
\begin{itemize}
    \item Dataset : 3500 organoïdes synthétiques (train)
    \item Batch size : 32 graphes
    \item Époques : 200
    \item Augmentation : Rotations aléatoires 3D, jitter, variations d'intensités
    \item Durée : ~2 heures (GPU V100)
\end{itemize}

\subsubsection{Fine-tuning sur réels}

\textbf{Phase 2 : Adaptation au réel}
\begin{itemize}
    \item Initialisation : Poids pré-entraînés (sauf classification head, réinitialisée)
    \item Dataset : N organoïdes réels annotés (typiquement N = 200-500)
    \item Learning rate réduit : $10^{-4}$ (fine-tuning)
    \item Époques : 100
    \item Régularisation accrue : Dropout 0.2, weight decay $10^{-4}$
\end{itemize}

\subsubsection{Entraînement from scratch sur réels}

\textbf{Baseline sans pré-entraînement :}
Pour comparaison, nous entraînons également des modèles directement sur données réelles depuis initialisation aléatoire.

\subsection{Validation croisée}

\subsubsection{Stratégie}

Étant donné les datasets de taille limitée, nous adoptons :

\textbf{5-fold stratified cross-validation :}
\begin{enumerate}
    \item Partitionner dataset en 5 folds stratifiés (distribution de classes préservée)
    \item Pour chaque fold :
    \begin{enumerate}
        \item Entraîner sur 4 folds
        \item Valider sur 1 fold
    \end{enumerate}
    \item Agréger les résultats (moyenne et écart-type des métriques)
\end{enumerate}

\textbf{Nested cross-validation :}
Pour sélection d'hyperparamètres non-biaisée :
\begin{itemize}
    \item Outer loop : 5-fold pour estimation de performance
    \item Inner loop : 3-fold sur train set pour tuning hyperparamètres
\end{itemize}

\subsubsection{Importance du stratification}

La stratification assure que chaque fold contient une proportion représentative de chaque classe, crucial avec petits datasets et classes potentiellement déséquilibrées.

\subsection{Recherche d'hyperparamètres}

\subsubsection{Espace de recherche}

Hyperparamètres explorés :
\begin{itemize}
    \item Nombre de couches : \{3, 4, 5, 6\}
    \item Dimension cachée : \{64, 128, 256, 512\}
    \item Learning rate : \{$10^{-4}$, $5 \times 10^{-4}$, $10^{-3}$, $5 \times 10^{-3}$\}
    \item Dropout : \{0.0, 0.1, 0.15, 0.2, 0.3\}
    \item Batch size : \{16, 32, 64\}
    \item K (connectivité K-NN) : \{5, 8, 10, 12, 15\}
\end{itemize}

\subsubsection{Stratégie de recherche}

\textbf{Random search :}
Plutôt que grid search (combinatoire, coûteux), nous échantillonnons aléatoirement 100 configurations et entraînons chacune pour 50 époques.

\textbf{Critère de sélection :}
Accuracy moyenne sur validation set du inner cross-validation loop.

\subsubsection{Résultats}

\textbf{Configuration optimale trouvée :}
\begin{itemize}
    \item Couches : 5
    \item Dimension : 256
    \item LR : $10^{-3}$
    \item Dropout : 0.15
    \item Batch : 32
    \item K : 10
\end{itemize}

\textbf{Sensibilité :}
Dimension cachée et nombre de couches sont les plus impactants. Learning rate et dropout ont un effet modéré dans les plages explorées.

\section{Implémentation et détails techniques}

\subsection{Stack technologique}

\textbf{Langages et frameworks :}
\begin{itemize}
    \item Python 3.9
    \item PyTorch~\cite{Paszke2019} 2.0 pour deep learning
    \item PyTorch Geometric~\cite{Fey2019} (PyG) 2.3 pour GNNs
    \item NumPy, SciPy pour calculs scientifiques
    \item scikit-image~\cite{VanDerWalt2014} pour traitement d'image
    \item scikit-learn pour ML classique et métriques
\end{itemize}

\textbf{Segmentation :}
\begin{itemize}
    \item Cellpose 2.2
    \item Interface programmatique (Python API)
\end{itemize}

\textbf{Visualisation :}
\begin{itemize}
    \item Matplotlib, Seaborn pour figures 2D
    \item Plotly pour visualisations 3D interactives
    \item napari pour inspection interactive de segmentations
    \item TensorBoard pour monitoring d'entraînement
\end{itemize}

\subsection{Structures de données}

\subsubsection{Format des graphes}

Nous utilisons le format `torch_geometric.data.Data` :
\begin{itemize}
    \item `x` : Features de nœuds (Tensor de taille $[N, D_f]$)
    \item `edge_index` : Indices d'arêtes (Tensor de taille $[2, |E|]$, format COO)
    \item `edge_attr` : Features d'arêtes (Tensor de taille $[|E|, D_e]$)
    \item `pos` : Coordonnées 3D (Tensor de taille $[N, 3]$)
    \item `y` : Label du graphe (Tensor scalaire ou vecteur)
\end{itemize}

\textbf{Batching :}
PyG gère automatiquement le batching de graphes de tailles différentes via graphe disjoint (union de graphes dans un grand graphe sparse).

\subsubsection{Sauvegarde et chargement}

Les graphes pré-calculés sont sauvegardés en format PyTorch (`.pt`) ou pickle compressé pour accélérer l'entraînement (éviter recalcul de segmentation et graphe construction à chaque run).

\subsection{Optimisations computationnelles}

\subsubsection{Calculs sparse}

Les matrices d'adjacence sont stockées en format sparse (COO ou CSR) pour efficacité mémoire et computationnelle.

\subsubsection{Mixed precision training}

Utilisation de FP16 (float 16 bits) pour :
\begin{itemize}
    \item Réduction mémoire (2×)
    \item Accélération calculs GPU (Tensor Cores)
    \item Maintien de FP32 pour accumulateurs (précision numérique)
\end{itemize}

Via `torch.cuda.amp` (Automatic Mixed Precision).

\subsubsection{Data loading parallèle}

\begin{itemize}
    \item DataLoader avec num\_workers = 4 (threads CPU)
    \item Prefetching : chargement du batch suivant pendant traitement du batch courant
    \item Pin memory pour transfert CPU→GPU accéléré
\end{itemize}

\section{Récapitulatif méthodologique}

Ce chapitre a décrit en détail chaque composante de notre pipeline innovant pour l'analyse automatisée d'organoïdes 3D via Graph Neural Networks.

\textbf{Prétraitement et segmentation} : Le pipeline débute par un prétraitement robuste (normalisation d'intensité par percentiles, débruitage multi-échelle, corrections d'artefacts optiques) suivi d'une segmentation state-of-the-art via Faster Cellpose — notre contribution méthodologique optimisant Cellpose par knowledge distillation et pruning, atteignant F1=0.95 avec un gain de vitesse 5× crucial pour traiter nos 2272 organoïdes réels.

\textbf{Données réelles et tâches} : Notre dataset collaboratif comprend 1311 échantillons imagés (2272 organoïdes extraits), dominés par deux phénotypes : choux-fleurs (55.9\%, agrégation spatiale forte) et cystiques (40.3\%, répartition homogène). Nous adressons trois tâches complémentaires : classification binaire choux-fleurs vs cystiques (tâche principale), régression du coefficient de clustering sur synthétiques (pré-entraînement), et régression de la déformation morphologique sur réels (quantification fine).

\textbf{Génération synthétique} : Contribution majeure, nos ~3000 organoïdes synthétiques sont générés via processus ponctuels (Poisson homogène et Matérn cluster) formant un continuum contrôlé de patterns spatiaux. La construction de Voronoï 3D produit des géométries cellulaires réalistes, validées statistiquement par fonctions de Ripley et tests KS. Ces synthétiques servent au pré-entraînement et à l'apprentissage de représentations géométriques transférables.

\textbf{Construction de graphes} : Extraction de 27 features par cellule (géométrie, morphologie, intensités, texture), puis construction via stratégie K-NN hybride (k=10) équilibrant connectivité, signification biologique et efficacité computationnelle.

\textbf{Architectures et entraînement} : EGNN équivariant comme modèle principal exploitant pleinement la géométrie 3D, comparé à baselines GNN standards (GCN, GAT, GIN) pour ablations. Stratégie d'entraînement en deux phases : pré-entraînement sur synthétiques (régression clustering) puis fine-tuning sur réels (classification/régression), avec validation croisée 5-fold et recherche d'hyperparamètres systématique.

Le Chapitre 5 présentera les résultats expérimentaux obtenus avec cette méthodologie, validant empiriquement les choix effectués et quantifiant les performances sur les tâches de classification et de régression.
