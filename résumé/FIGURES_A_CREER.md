# üìä Figures √† cr√©er pour la th√®se

Ce document liste toutes les figures prioritaires √† cr√©er, avec leurs sp√©cifications d√©taill√©es.

---

## üî¥ **PRIORIT√â 1 : Figures essentielles (URGENT)**

### **Figure 4.1 : Pipeline complet de bout en bout** ‚≠ê‚≠ê‚≠ê
**Emplacement :** Chapitre 4, Section 4.1 (Vue d'ensemble du pipeline)  
**Type :** Flowchart horizontal multi-√©tapes  

**Contenu :**
```
[Image 3D TIFF] 
    ‚Üì (2048√ó2048√ó200, 2 Go)
[Pr√©traitement]
    ‚Ä¢ Normalisation intensit√©s
    ‚Ä¢ D√©bruitage (Gaussian œÉ=1)
    ‚Üì
[Segmentation - Faster Cellpose]
    ‚Ä¢ D√©tection noyaux
    ‚Ä¢ F1=0.95, 0.5h/√©chantillon
    ‚Üì
[Extraction point cloud]
    ‚Ä¢ Centroides cellules
    ‚Ä¢ Features morphologiques (27D)
    ‚Üì
[Clustering DBSCAN]
    ‚Ä¢ S√©paration organo√Ødes
    ‚Ä¢ eps=30Œºm, min_samples=20
    ‚Üì
[Construction graphe]
    ‚Ä¢ K-NN (k=10)
    ‚Ä¢ ~250 n≈ìuds, ~2500 ar√™tes
    ‚Üì
[EGNN Classification]
    ‚Ä¢ 3 layers, 128 hidden dim
    ‚Ä¢ Output: 4 classes
    ‚Üì
[Pr√©diction ph√©notype]
    ‚Ä¢ Chouxfleurs / Cystiques / Compact / K√©ratinis√©s
```

**Annotations :**
- Tailles donn√©es √† chaque √©tape
- Temps de calcul (0.5h segmentation, 0.1s classification)
- Compression : 2 Go ‚Üí 5 Mo graphe

**Fichier LaTeX :**
```latex
\begin{figure}[htbp]
\centering
% TODO: Ins√©rer image flowchart_pipeline.pdf
\includegraphics[width=\textwidth]{chapitre4/img/flowchart_pipeline.pdf}
\caption{Pipeline complet d'analyse d'organo√Ødes 3D. De l'image confocale brute (2 Go) √† la pr√©diction de ph√©notype, chaque √©tape compresse et enrichit l'information structurelle. La repr√©sentation graphe finale (5 Mo) pr√©serve les relations spatiales biologiquement pertinentes tout en r√©duisant drastiquement la dimensionnalit√©.}
\label{fig:pipeline_complet}
\end{figure}
```

---

### **Figure 5.3 : Matrice de confusion 4√ó4 (dataset r√©el)** ‚≠ê‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.4.1 (ligne 567)  
**Type :** Heatmap matrice confusion  

**Donn√©es :**
```
              Pr√©dit ‚Üí
Vrai ‚Üì     Choux  Cyst  Comp  K√©rat
Chouxfleurs  194    13    3     1      (211 total)
Cystiques     11   107    4     1      (123)
Compact        2     1    3     0      (6)
K√©ratinis√©s    0     1    0     1      (2)
```

**Sp√©cifications visuelles :**
- Colormap : Vert (correct, diagonale) ‚Üí Blanc ‚Üí Rouge (erreurs)
- Annotations : Nombres dans cellules + pourcentages
- Diagonale en gras
- Lignes/colonnes totaux

**Code Python pour g√©n√©ration :**
```python
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np

confusion_matrix = np.array([
    [194, 13, 3, 1],
    [11, 107, 4, 1],
    [2, 1, 3, 0],
    [0, 1, 0, 1]
])

labels = ['Chouxfleurs', 'Cystiques', 'Compact', 'K√©ratinis√©s']

fig, ax = plt.subplots(figsize=(8, 7))
sns.heatmap(confusion_matrix, annot=True, fmt='d', cmap='RdYlGn', 
            xticklabels=labels, yticklabels=labels, 
            cbar_kws={'label': 'Nombre de pr√©dictions'},
            linewidths=0.5, linecolor='gray', ax=ax)
ax.set_xlabel('Pr√©dit', fontsize=12, fontweight='bold')
ax.set_ylabel('Vrai', fontsize=12, fontweight='bold')
ax.set_title('Matrice de confusion - EGNN pr√©-entra√Æn√©\nTest set (342 organo√Ødes)', 
             fontsize=14, fontweight='bold')

# Accuracy totale
acc = np.trace(confusion_matrix) / confusion_matrix.sum()
ax.text(0.5, -0.15, f'Accuracy globale: {acc:.1%}', 
        transform=ax.transAxes, ha='center', fontsize=11, style='italic')

plt.tight_layout()
plt.savefig('confusion_matrix.pdf', dpi=300, bbox_inches='tight')
```

**Fichier LaTeX :**
```latex
\begin{figure}[htbp]
\centering
\includegraphics[width=0.75\textwidth]{chapitre5/img/confusion_matrix.pdf}
\caption{Matrice de confusion du mod√®le EGNN pr√©-entra√Æn√© sur le test set (342 organo√Ødes). La diagonale forte (305/342 = 89.2\%) d√©montre une bonne capacit√© discriminative. Les confusions principales (24 cas) surviennent entre Chouxfleurs et Cystiques, refl√©tant une ambigu√Øt√© biologique r√©elle rapport√©e par les experts.}
\label{fig:confusion_matrix_reel}
\end{figure}
```

---

### **Figure 5.4 : Barplot comparaison 5 m√©thodes** ‚≠ê‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.4.3 (apr√®s ligne 655)  
**Type :** Barplot group√© avec erreurs

**Donn√©es :**
```
M√©thode                | Accuracy  | F1 weighted  | Temps (h)
--------------------- |-----------|--------------|----------
Random Forest         | 72.4¬±3.1% | 0.701¬±0.028  | 0.008
CNN 3D                | 81.2¬±2.8% | 0.806¬±0.024  | 12.0
EGNN from scratch     | 76.3¬±3.4% | 0.754¬±0.031  | 1.5
GAT                   | 79.1¬±2.6% | 0.782¬±0.025  | 1.8
EGNN pr√©-entra√Æn√©     | 84.6¬±2.1% | 0.843¬±0.019  | 0.5 (ft)
```

**Sp√©cifications visuelles :**
- 3 groupes de barres (Accuracy, F1, Log Temps)
- Barres d'erreur (√©cart-type)
- EGNN pr√©-entra√Æn√© en couleur diff√©rente (vert)
- Ligne pointill√©e "Expertise humaine" √† 81.3% (Expert 1)

**Code Python :**
```python
import matplotlib.pyplot as plt
import numpy as np

methods = ['Random\nForest', 'CNN 3D', 'EGNN\nscratch', 'GAT', 'EGNN\npre-trained']
accuracy = [72.4, 81.2, 76.3, 79.1, 84.6]
accuracy_std = [3.1, 2.8, 3.4, 2.6, 2.1]
f1 = [0.701, 0.806, 0.754, 0.782, 0.843]
f1_std = [0.028, 0.024, 0.031, 0.025, 0.019]

colors = ['#95a5a6', '#3498db', '#e74c3c', '#9b59b6', '#27ae60']

fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))

# Accuracy
x = np.arange(len(methods))
bars1 = ax1.bar(x, accuracy, yerr=accuracy_std, capsize=5, color=colors, 
                edgecolor='black', linewidth=1.5, alpha=0.8)
ax1.axhline(81.3, color='red', linestyle='--', linewidth=2, label='Expert 1 (81.3%)')
ax1.set_ylabel('Accuracy (%)', fontsize=12, fontweight='bold')
ax1.set_xticks(x)
ax1.set_xticklabels(methods, fontsize=10)
ax1.set_ylim(65, 90)
ax1.grid(axis='y', alpha=0.3)
ax1.legend(fontsize=10)
ax1.set_title('Performances de classification', fontsize=13, fontweight='bold')

# F1 weighted
bars2 = ax2.bar(x, f1, yerr=f1_std, capsize=5, color=colors, 
                edgecolor='black', linewidth=1.5, alpha=0.8)
ax2.set_ylabel('F1 weighted', fontsize=12, fontweight='bold')
ax2.set_xticks(x)
ax2.set_xticklabels(methods, fontsize=10)
ax2.set_ylim(0.65, 0.90)
ax2.grid(axis='y', alpha=0.3)
ax2.set_title('Score F1 pond√©r√©', fontsize=13, fontweight='bold')

plt.tight_layout()
plt.savefig('comparison_methods.pdf', dpi=300, bbox_inches='tight')
```

**Fichier LaTeX :**
```latex
\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{chapitre5/img/comparison_methods.pdf}
\caption{Comparaison des performances de 5 approches de classification sur OrganoProstate-2K. EGNN pr√©-entra√Æn√© surpasse toutes les m√©thodes (84.6\% accuracy, F1=0.843), y compris l'expertise humaine individuelle (Expert 1 : 81.3\%). Le pr√©-entra√Ænement sur donn√©es synth√©tiques am√©liore significativement les performances (+8.3 points vs from scratch) tout en r√©duisant le temps de fine-tuning (0.5h vs 1.5h).}
\label{fig:comparison_methods}
\end{figure}
```

---

### **Figure 5.5 : Courbes data efficiency (learning curves)** ‚≠ê‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.4.4 (ligne 663)  
**Type :** Line plot avec 2 courbes

**Donn√©es :**
```
% donn√©es  |  From scratch  |  Pre-trained  |  Gain
10%        |  58.3%         |  71.2%        |  +12.9%
25%        |  67.1%         |  78.4%        |  +11.3%
50%        |  72.8%         |  82.1%        |  +9.3%
75%        |  75.2%         |  83.7%        |  +8.5%
100%       |  76.3%         |  84.6%        |  +8.3%
```

**Sp√©cifications visuelles :**
- Axe X : % donn√©es (log scale possible)
- Axe Y : Accuracy (%)
- 2 courbes : From scratch (rouge), Pre-trained (vert)
- Marqueurs : points ronds
- Zone gris√©e : gains du pr√©-entra√Ænement
- Annotations : gain √† 25% (+11.3 points)

**Code Python :**
```python
import matplotlib.pyplot as plt
import numpy as np

pct_data = [10, 25, 50, 75, 100]
scratch = [58.3, 67.1, 72.8, 75.2, 76.3]
pretrained = [71.2, 78.4, 82.1, 83.7, 84.6]

fig, ax = plt.subplots(figsize=(10, 6))

ax.plot(pct_data, scratch, 'o-', color='#e74c3c', linewidth=2.5, 
        markersize=10, label='EGNN from scratch', markeredgecolor='black')
ax.plot(pct_data, pretrained, 'o-', color='#27ae60', linewidth=2.5, 
        markersize=10, label='EGNN pr√©-entra√Æn√©', markeredgecolor='black')

# Zone gain
ax.fill_between(pct_data, scratch, pretrained, alpha=0.2, color='green', 
                label='Gain pr√©-entra√Ænement')

# Annotation cl√©
ax.annotate('Avec 25% donn√©es,\npr√©-train = scratch 100%', 
            xy=(25, 78.4), xytext=(40, 72), fontsize=11,
            arrowprops=dict(arrowstyle='->', lw=2, color='black'),
            bbox=dict(boxstyle='round,pad=0.5', facecolor='yellow', alpha=0.7))

ax.set_xlabel('Pourcentage des donn√©es d\'entra√Ænement (%)', fontsize=12, fontweight='bold')
ax.set_ylabel('Accuracy test set (%)', fontsize=12, fontweight='bold')
ax.set_title('Data efficiency : Impact du pr√©-entra√Ænement synth√©tique', 
             fontsize=14, fontweight='bold')
ax.grid(True, alpha=0.3)
ax.legend(fontsize=11, loc='lower right')
ax.set_xlim(5, 105)
ax.set_ylim(55, 88)

plt.tight_layout()
plt.savefig('data_efficiency.pdf', dpi=300, bbox_inches='tight')
```

**Fichier LaTeX :**
```latex
\begin{figure}[htbp]
\centering
\includegraphics[width=0.85\textwidth]{chapitre5/img/data_efficiency.pdf}
\caption{Courbes d'apprentissage d√©montrant l'efficacit√© du transfer learning. Le mod√®le pr√©-entra√Æn√© sur donn√©es synth√©tiques atteint avec seulement 25\% des annotations (398 organo√Ødes) les performances du mod√®le from scratch entra√Æn√© avec 100\% des donn√©es (1,590 organo√Ødes). R√©duction de 75\% du besoin en annotations expertes, critique pour l'adoption pratique.}
\label{fig:data_efficiency}
\end{figure}
```

---

## üü° **PRIORIT√â 2 : Figures importantes**

### **Figure 3.X : Organo√Øde ‚Üí Graphe (transformation)** ‚≠ê‚≠ê
**Emplacement :** Chapitre 3, Section 3.1 ou Chapitre 4, Section 4.5  
**Type :** S√©rie 3 images c√¥te-√†-c√¥te

**Contenu :**
```
[A] Image 3D volume rendering  ‚Üí  [B] Point cloud 3D  ‚Üí  [C] Graphe K-NN
    (Organo√Øde color√©)            (250 points)           (ar√™tes K-NN)
```

**Annotations :**
- (A) 2048√ó2048√ó200 voxels, 2 Go
- (B) 250 centroides, 27 features/cellule
- (C) k=10, 2,500 ar√™tes, 5 Mo

**Fichier LaTeX :**
```latex
\begin{figure}[htbp]
\centering
\includegraphics[width=\textwidth]{chapitre4/img/organoid_to_graph.pdf}
\caption{Transformation d'un organo√Øde de prostate en graphe g√©om√©trique. (A) Volume rendering 3D de l'organo√Øde segment√© (Faster Cellpose). (B) Extraction du nuage de points : centroides cellulaires avec features morphologiques (volume, sph√©ricit√©, intensit√©). (C) Construction du graphe K-NN (k=10) : chaque cellule est connect√©e √† ses 10 plus proches voisines. Cette repr√©sentation compresse l'information d'un facteur 400√ó (2 Go ‚Üí 5 Mo) tout en pr√©servant la structure relationnelle.}
\label{fig:organoid_to_graph}
\end{figure}
```

---

### **Figure 4.X : Comparaison 3 segmentations** ‚≠ê‚≠ê
**Emplacement :** Chapitre 4, Section 4.3.4 (apr√®s ligne 600)  
**Type :** Tableau comparatif + exemples visuels

**Contenu tableau :**
```
Crit√®re              | Ellipses    | Faster Cellpose | Cellpose original
--------------------|-------------|-----------------|------------------
F1-score            | 0.82        | 0.95            | 0.98
Temps/√©chantillon   | 0.1h        | 0.5h            | 12h
Speedup vs Cellpose | 120√ó        | 24√ó             | 1√ó
Faux positifs       | √âlev√©s      | Faibles         | Tr√®s faibles
Usage pipeline      | ‚ùå Non      | ‚úÖ OUI          | ‚ùå Trop lent
```

**+ 3 exemples visuels (slices 2D) :**
- Cellpose original (gold standard)
- Faster Cellpose (quasi-identique)
- Ellipses (sur-segmentation visible)

---

### **Figure 5.7.X : √âtude comparative stats vs GNN - Bruit gaussien** ‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.7.2  
**Type :** Line plot

**Donn√©es :**
```
œÉ_g     | Stats K   | Stats F   | GNN
--------|-----------|-----------|------
0       | 97%       | 98%       | 99%
0.1     | 93%       | 94%       | 97%
0.2     | 86%       | 88%       | 94%
0.3     | 75%       | 78%       | 89%
0.4     | 61%       | 64%       | 82%
```

**Sp√©cifications :**
- Axe X : œÉ_g (√©cart-type bruit gaussien)
- Axe Y : Accuracy (%)
- 3 courbes : Stats K (bleu), Stats F (vert), GNN (rouge)

---

### **Figure 5.7.Y : √âtude comparative - Bruit poivre-sel** ‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.7.2  
**Type :** Line plot similaire √† X

**Donn√©es :**
```
p_sp    | Stats K   | Stats F   | GNN
--------|-----------|-----------|------
0       | 97%       | 98%       | 99%
0.05    | 91%       | 92%       | 96%
0.10    | 82%       | 84%       | 92%
0.15    | 69%       | 72%       | 85%
0.20    | 53%       | 57%       | 76%
```

---

### **Figure 5.7.Z : G√©n√©ralisation g√©om√©trique (sph√®re ‚Üí ellipso√Øde)** ‚≠ê‚≠ê
**Emplacement :** Chapitre 5, Section 5.7.3  
**Type :** Barplot

**Donn√©es :**
```
Ratio aspect | Stats K | Stats F | GNN
-------------|---------|---------|-----
1.0 (sph√®re) | 97%     | 98%     | 99%
1.5          | 78%     | 81%     | 97%
2.0          | 62%     | 67%     | 95%
2.5          | 51%     | 56%     | 92%
```

---

## üü¢ **PRIORIT√â 3 : Figures compl√©mentaires (optionnelles)**

### **Figure 4.Y : Architecture EGNN d√©taill√©e**
- Sch√©ma bloc message passing
- 3 layers avec dimensions

### **Figure 5.X : ROC curves (4 classes, one-vs-rest)**
- AUC par classe

### **Figure 5.Z : Attention maps 3D**
- Visualisation cellules importantes (GNNExplainer)

### **Figure 5.W : t-SNE embeddings**
- Repr√©sentation latente 4 classes

---

## üìù **R√©sum√© priorit√©s**

### **√Ä cr√©er ABSOLUMENT (avant soutenance) :**
1. ‚úÖ Figure 4.1 : Pipeline complet
2. ‚úÖ Figure 5.3 : Matrice confusion
3. ‚úÖ Figure 5.4 : Barplot comparaison m√©thodes
4. ‚úÖ Figure 5.5 : Courbes data efficiency

### **Fortement recommand√© :**
5. Figure 3.X/4.X : Organo√Øde ‚Üí Graphe
6. Figure 4.X : Comparaison segmentations
7. Figures 5.7.X-Y-Z : √âtude comparative (3 figures)

**Total minimum viable : 4 figures essentielles**  
**Total recommand√© : 7-10 figures**

---

## üõ†Ô∏è **Outils sugg√©r√©s**

- **Python** : matplotlib, seaborn, scikit-learn
- **3D rendering** : PyVista, Plotly, Mayavi
- **Graphes** : NetworkX, PyTorch Geometric visualization
- **Diagrammes** : draw.io, Inkscape, TikZ (LaTeX)

---

**Derni√®re mise √† jour :** 2025-10-14


