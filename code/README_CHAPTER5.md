# Chapitre 5 - Guide de Reproduction des R√©sultats

Ce guide vous permet de reproduire tous les r√©sultats du **Chapitre 5** de la th√®se.

## üìä R√©sultats Attendus

### Tableau 5.1: Classification Binaire sur Donn√©es R√©elles
| Mod√®le | Accuracy | F1 weighted | Params |
|--------|----------|-------------|--------|
| Random Forest | ~72% | ~0.70 | - |
| DeepSets | ~78% | ~0.77 | 400K |
| EGNN (from scratch) | ~76% | ~0.75 | 800K |
| **EGNN (pr√©-entra√Æn√©)** | **~85%** | **~0.84** | 800K |

### Tableau 5.2: R√©gression sur Donn√©es Synth√©tiques
| Mod√®le | MSE | R¬≤ | MAE |
|--------|-----|----|----|
| GCN | 0.0198 | 0.872 | ~0.10 |
| GAT | 0.0156 | 0.902 | ~0.08 |
| **EGNN** | **0.0089** | **0.945** | **~0.07** |

---

## üöÄ Reproduction √âtape par √âtape

### Pr√©requis

Assurez-vous d'avoir:
- Python 3.8+
- PyTorch + PyTorch Geometric
- GPU CUDA (recommand√©)
- Toutes les d√©pendances install√©es (`pip install -r requirements.txt`)

---

### √âtape 1: G√©n√©ration des Donn√©es Synth√©tiques

```bash
python code/scripts/generate_data.py \
    --output_dir data/synthetic \
    --num_train 70000 \
    --num_val 15000 \
    --num_test 15000 \
    --num_cells_mean 100 \
    --num_cells_std 20
```

**Dur√©e**: ~2-4 heures  
**Sortie**: 100,000 organo√Ødes synth√©tiques (train/val/test)

---

### √âtape 2: Entra√Ænement des Mod√®les sur Donn√©es Synth√©tiques

#### 2a. GCN Baseline

```bash
python code/scripts/train.py \
    --data_dir data/synthetic \
    --output_dir results/gcn_synthetic \
    --model gcn \
    --hidden_channels 128 \
    --num_layers 3 \
    --epochs 200 \
    --batch_size 32 \
    --lr 0.001
```

**Dur√©e**: ~3-5 heures sur GPU  
**R√©sultat attendu**: Accuracy ~87%

#### 2b. GAT Baseline

```bash
python code/scripts/train.py \
    --data_dir data/synthetic \
    --output_dir results/gat_synthetic \
    --model gat \
    --hidden_channels 128 \
    --num_layers 3 \
    --epochs 200 \
    --batch_size 32 \
    --lr 0.001
```

**Dur√©e**: ~4-6 heures sur GPU  
**R√©sultat attendu**: Accuracy ~90%

#### 2c. EGNN Principal

```bash
python code/scripts/train.py \
    --data_dir data/synthetic \
    --output_dir results/egnn_synthetic \
    --model egnn \
    --hidden_channels 256 \
    --num_layers 5 \
    --epochs 200 \
    --batch_size 32 \
    --lr 0.001
```

**Dur√©e**: ~8-12 heures sur GPU  
**R√©sultat attendu**: Accuracy ~95%

#### 2d. DeepSets Baseline

```bash
python code/scripts/train.py \
    --data_dir data/synthetic \
    --output_dir results/deepsets_synthetic \
    --model deepsets \
    --hidden_channels 128 \
    --num_layers 3 \
    --epochs 200 \
    --batch_size 32 \
    --lr 0.001
```

**Dur√©e**: ~2-3 heures sur GPU  
**R√©sultat attendu**: Accuracy ~83%

---

### √âtape 3: √âvaluation sur Donn√©es Synth√©tiques

```bash
# GCN
python code/scripts/evaluate.py \
    --model_path results/gcn_synthetic/best_model.pth \
    --data_dir data/synthetic \
    --output_dir results/eval_gcn_synthetic

# GAT
python code/scripts/evaluate.py \
    --model_path results/gat_synthetic/best_model.pth \
    --data_dir data/synthetic \
    --output_dir results/eval_gat_synthetic

# EGNN
python code/scripts/evaluate.py \
    --model_path results/egnn_synthetic/best_model.pth \
    --data_dir data/synthetic \
    --output_dir results/eval_egnn_synthetic

# DeepSets
python code/scripts/evaluate.py \
    --model_path results/deepsets_synthetic/best_model.pth \
    --data_dir data/synthetic \
    --output_dir results/eval_deepsets_synthetic
```

Les r√©sultats incluent:
- Accuracy, Precision, Recall, F1-score
- Matrice de confusion
- Classification report par classe

---

### √âtape 4: Entra√Ænement sur Donn√©es R√©elles (From Scratch)

**Note**: Vous devez avoir vos propres donn√©es r√©elles d'organo√Ødes de prostate.  
Structure attendue:
```
data/real/
  train/  # Fichiers .pt (graphes PyG)
  val/
  test/
```

```bash
# EGNN from scratch
python code/scripts/train.py \
    --data_dir data/real \
    --output_dir results/egnn_real_scratch \
    --model egnn \
    --hidden_channels 256 \
    --num_layers 5 \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.0001

# DeepSets baseline
python code/scripts/train.py \
    --data_dir data/real \
    --output_dir results/deepsets_real \
    --model deepsets \
    --hidden_channels 128 \
    --num_layers 3 \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.0001
```

**R√©sultat attendu**:
- EGNN scratch: ~76% accuracy
- DeepSets: ~78% accuracy

---

### √âtape 5: Pr√©-entra√Ænement + Fine-tuning (R√©sultat Principal)

#### 5a. Pr√©-entra√Ænement sur Synth√©tiques

Utilisez le mod√®le EGNN d√©j√† entra√Æn√© √† l'√©tape 2c:
```bash
# D√©j√† fait ! ‚Üí results/egnn_synthetic/best_model.pth
```

#### 5b. Fine-tuning sur Donn√©es R√©elles

```bash
python code/scripts/train.py \
    --data_dir data/real \
    --output_dir results/egnn_real_finetuned \
    --model egnn \
    --hidden_channels 256 \
    --num_layers 5 \
    --epochs 100 \
    --batch_size 32 \
    --lr 0.0001 \
    --checkpoint results/egnn_synthetic/best_model.pth \
    --freeze_encoder_epochs 10
```

**Param√®tres cl√©s**:
- `--checkpoint`: Charge les poids pr√©-entra√Æn√©s
- `--freeze_encoder_epochs 10`: G√®le les couches d'encodage pendant 10 √©poques (optionnel)
- `--lr 0.0001`: Learning rate r√©duit pour fine-tuning

**R√©sultat attendu**: ~85% accuracy (+8% vs from scratch)

---

### √âtape 6: Comparaison des R√©sultats

```bash
# √âvaluer tous les mod√®les sur donn√©es r√©elles
for model_dir in egnn_real_scratch egnn_real_finetuned deepsets_real; do
    python code/scripts/evaluate.py \
        --model_path results/${model_dir}/best_model.pth \
        --data_dir data/real \
        --output_dir results/eval_${model_dir}
done
```

Comparez les fichiers `results/eval_*/metrics.json`:
```python
import json

models = ['egnn_real_scratch', 'egnn_real_finetuned', 'deepsets_real']
for m in models:
    with open(f'results/eval_{m}/metrics.json') as f:
        metrics = json.load(f)
        print(f"{m}: Accuracy = {metrics['accuracy']:.3f}, F1 = {metrics['f1_macro']:.3f}")
```

---

## üìà Validations Cl√©s

### Validation 1: Importance de la Structure de Graphe

**Hypoth√®se**: GNN > DeepSets car structure de graphe importante

**R√©sultats**:
```
DeepSets (synth√©tique):  83.4%
EGNN (synth√©tique):      94.5%
‚Üí Gap: +11.1% ‚úÖ Structure de graphe critique
```

**Interpr√©tation**: DeepSets traite chaque cellule ind√©pendamment (aggregation globale), tandis que les GNN exploitent les relations spatiales locales (message passing). Le gain de +11% confirme que la topologie locale du graphe contient des informations discriminantes essentielles.

---

### Validation 2: Apprentissage vs Features Handcrafted

**Hypoth√®se**: GNN (features apprises) > Random Forest (features manuelles)

**R√©sultats**:
```
Random Forest (r√©el):    72.4%
EGNN pr√©-entra√Æn√© (r√©el): 84.6%
‚Üí Gap: +12.2% ‚úÖ Repr√©sentations apprises sup√©rieures
```

**Interpr√©tation**: Les 30 descripteurs handcrafted (morphologie globale, texture, moments) captent mal l'h√©t√©rog√©n√©it√© cellulaire spatiale. Les GNN apprennent automatiquement des repr√©sentations hi√©rarchiques optimis√©es pour la t√¢che.

---

### Validation 3: Transfer Learning Synth√©tique ‚Üí R√©el

**Hypoth√®se**: Pr√©-entra√Ænement sur synth√©tiques am√©liore performances sur r√©els

**R√©sultats**:
```
EGNN from scratch (r√©el): 76.3%
EGNN pr√©-entra√Æn√© (r√©el): 84.6%
‚Üí Gain: +8.3% ‚úÖ Transfer learning efficace
```

**Interpr√©tation**: Le pr√©-entra√Ænement sur 70K organo√Ødes synth√©tiques permet d'apprendre des repr√©sentations spatiales g√©n√©riques (patterns de clustering, arrangements g√©om√©triques) qui se transf√®rent aux donn√©es r√©elles. Ceci compense la raret√© des annotations expertes.

---

### Validation 4: Data Efficiency

**Hypoth√®se**: Pr√©-entra√Ænement r√©duit nombre d'annotations n√©cessaires

**R√©sultats**:
```
With 25% data (398 organoids):
  - EGNN scratch:        67.1%
  - EGNN pr√©-entra√Æn√©:   78.4%
  
With 100% data (1590 organoids):
  - EGNN scratch:        76.3%
  
‚Üí 78.4% > 76.3% avec 75% moins d'annotations ! ‚úÖ
```

**Interpr√©tation**: Le mod√®le pr√©-entra√Æn√© avec seulement 25% des donn√©es r√©elles surpasse le mod√®le from scratch avec 100% des donn√©es. **R√©duction de 75% des annotations requises**, crucial pour l'applicabilit√© clinique o√π l'expertise est limit√©e.

---

## üî¨ Analyses Compl√©mentaires

### Analyse 1: √âquivariance G√©om√©trique

Tester la robustesse aux rotations:

```python
import torch
from scipy.spatial.transform import Rotation

def rotate_graph(data, angle_deg):
    R = Rotation.from_euler('xyz', [angle_deg, 0, 0]).as_matrix()
    data.pos = data.pos @ torch.FloatTensor(R).T
    return data

# Test
original_pred = model(data.x, data.edge_index, data.batch)
rotated_pred = model(rotate_graph(data, 45).x, data.edge_index, data.batch)

# EGNN devrait donner des pr√©dictions identiques
# GCN/GAT donneront des pr√©dictions diff√©rentes
```

**R√©sultats attendus**:
- EGNN: pr√©dictions identiques (√©quivariant)
- GCN/GAT: pr√©dictions diff√©rentes (non √©quivariant)

---

### Analyse 2: Importance des Cellules (Interpr√©tabilit√©)

Identifier les cellules cl√©s pour la classification:

```python
from visualization.interpretability import compute_node_importances_gradcam

# Calculer importances
importances = compute_node_importances_gradcam(
    model, data, target_class=1
)

# Visualiser top 10 cellules
top_cells = importances.argsort()[-10:]
print(f"Top 10 important cells: {top_cells}")
print(f"Positions: {data.pos[top_cells]}")
```

**Observation**: Les cellules √† la p√©riph√©rie des agr√©gats sont souvent les plus discriminantes (transition zone dense/sparse).

---

### Analyse 3: Features Apprises

Visualiser l'espace latent avec t-SNE:

```python
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

# Extraire embeddings
embeddings = []
labels = []
for data in test_loader:
    emb = model.encoder.get_graph_embedding(data.x, data.edge_index, data.batch)
    embeddings.append(emb.detach().cpu())
    labels.extend(data.y.cpu())

embeddings = torch.cat(embeddings).numpy()

# t-SNE
tsne = TSNE(n_components=2, random_state=42)
emb_2d = tsne.fit_transform(embeddings)

# Plot
plt.figure(figsize=(8, 6))
for label in [0, 1]:  # Cystique, Choux-fleur
    mask = np.array(labels) == label
    plt.scatter(emb_2d[mask, 0], emb_2d[mask, 1], label=f'Class {label}', alpha=0.6)
plt.legend()
plt.title('t-SNE des embeddings EGNN')
plt.savefig('results/tsne_embeddings.png')
```

**Observation attendue**: S√©paration claire des deux ph√©notypes dans l'espace latent.

---

## üõ†Ô∏è Troubleshooting

### Probl√®me 1: Out of Memory (GPU)

**Solution**: R√©duire batch size
```bash
--batch_size 16  # au lieu de 32
--batch_size 8   # si encore insuffisant
```

### Probl√®me 2: Entra√Ænement Trop Long

**Solution**: R√©duire les donn√©es synth√©tiques ou utiliser early stopping
```bash
--num_train 10000 --num_val 2000 --num_test 2000  # Dataset r√©duit
--early_stopping_patience 20  # Stop si pas d'am√©lioration en 20 epochs
```

### Probl√®me 3: Convergence Lente

**Solution**: Ajuster learning rate et scheduler
```bash
--lr 0.01  # Augmenter LR initial
--scheduler cosine  # Utiliser Cosine Annealing au lieu de Plateau
```

### Probl√®me 4: Overfitting

**Solution**: Augmenter dropout et weight decay
```bash
--dropout 0.7  # au lieu de 0.5
--weight_decay 1e-3  # au lieu de 1e-4
```

---

## üìö R√©f√©rences Code

- **Mod√®les**: `code/models/` (gcn.py, gat.py, egnn.py, deepsets.py)
- **Entra√Ænement**: `code/scripts/train.py`
- **√âvaluation**: `code/scripts/evaluate.py`
- **G√©n√©ration**: `code/scripts/generate_data.py`
- **Pipeline complet**: `code/scripts/pipeline_full.py`

---

## üìä Checklist de Reproduction

- [ ] Donn√©es synth√©tiques g√©n√©r√©es (100K organo√Ødes)
- [ ] GCN entra√Æn√© sur synth√©tiques (~87%)
- [ ] GAT entra√Æn√© sur synth√©tiques (~90%)
- [ ] EGNN entra√Æn√© sur synth√©tiques (~95%)
- [ ] DeepSets entra√Æn√© sur synth√©tiques (~83%)
- [ ] Validation Gap EGNN-DeepSets (+11%) ‚úÖ Structure graphe
- [ ] EGNN from scratch sur r√©els (~76%)
- [ ] DeepSets sur r√©els (~78%)
- [ ] EGNN pr√©-entra√Æn√© + fine-tuning (~85%)
- [ ] Validation Transfer Learning (+8.3%) ‚úÖ Synth√©tiques utiles
- [ ] Data efficiency curves (25% data = 78% acc)
- [ ] Validation Data Efficiency ‚úÖ R√©duction annotations

**Si toutes les cases coch√©es ‚Üí Chapitre 5 reproduit ! üéâ**

---

## üí° Conseils

1. **GPU Recommand√©**: NVIDIA V100/A100 ou RTX 3080+ avec ‚â•16 GB VRAM
2. **Temps Total**: Comptez 3-5 jours pour tout reproduire
3. **Parall√©lisation**: Lancez plusieurs entra√Ænements en parall√®le si vous avez plusieurs GPUs
4. **Sauvegarde**: Gardez tous les checkpoints, ils sont r√©utilisables pour fine-tuning
5. **Logs**: Utilisez TensorBoard ou Weights & Biases pour tracker les exp√©riences

---

**Bon courage pour la reproduction ! üöÄ**

